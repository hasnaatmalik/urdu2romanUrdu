{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ---------------------------\n# Step 1: Setup\n# ---------------------------\n\n# Import required libraries\nimport torch\nimport sentencepiece as spm\nimport numpy as np\nimport pandas as pd\nimport random\nimport os\n\n# Set random seeds for reproducibility\nSEED = 42\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\n# Detect device (CPU or GPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T17:36:13.270490Z","iopub.execute_input":"2025-09-25T17:36:13.270839Z","iopub.status.idle":"2025-09-25T17:36:13.715861Z","shell.execute_reply.started":"2025-09-25T17:36:13.270815Z","shell.execute_reply":"2025-09-25T17:36:13.715179Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\n# ---------------------------\n# Step 2: Dataset Import + Normalization\n# ---------------------------\n\n# Clone repo and unzip dataset\n!git clone https://github.com/amir9ume/urdu_ghazals_rekhta.git\n!unzip -q /kaggle/working/urdu_ghazals_rekhta/dataset/dataset.zip -d /kaggle/working/urdu_ghazals_rekhta/dataset\n\nimport os\nimport unicodedata\nimport re\nfrom itertools import zip_longest\n\n# Dataset path (Kaggle)\nBASE_DIR = \"/kaggle/working/urdu_ghazals_rekhta/dataset/dataset\"\n\n# Output normalized corpus files\nSRC_FILE = \"/kaggle/working/urdu.txt\"    # Urdu side\nTGT_FILE = \"/kaggle/working/roman.txt\"   # Roman/English side\n\n# --- Normalization functions ---\ndef is_letter(ch):\n    return ch.isalpha()\n\ndef remove_inner_dots(s: str) -> str:\n    if not s:\n        return s\n    out = []\n    L = len(s)\n    for i, ch in enumerate(s):\n        if ch == '.':\n            prev_is_letter = (i - 1 >= 0 and is_letter(s[i-1]))\n            next_is_letter = (i + 1 < L and is_letter(s[i+1]))\n            if prev_is_letter and next_is_letter:\n                continue\n            else:\n                out.append(ch)\n        else:\n            out.append(ch)\n    return \"\".join(out)\n\ndef normalize_english(text: str) -> str:\n    if not text:\n        return \"\"\n    text = text.lower()\n    text = unicodedata.normalize(\"NFKD\", text)\n    text = text.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n    text = remove_inner_dots(text)\n    text = re.sub(r\"[‘’'\\\"`]\", \"\", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\ndef normalize_urdu(text: str) -> str:\n    if not text:\n        return \"\"\n    text = unicodedata.normalize(\"NFC\", text)\n    cleaned_chars = []\n    for c in text:\n        cp = ord(c)\n        if (0xFB50 <= cp <= 0xFDFF) or (0xFE70 <= cp <= 0xFEFF):\n            continue\n        cleaned_chars.append(c)\n    text = \"\".join(cleaned_chars)\n    text = text.replace(\"ؔ\", \"\")\n    text = remove_inner_dots(text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\n# --- File processor ---\ndef process_pair_files(en_file_path, ur_file_path, src_out, tgt_out):\n    with open(en_file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as enf, \\\n         open(ur_file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as urf:\n        for en_line, ur_line in zip_longest(enf, urf, fillvalue=\"\"):\n            en_line = en_line.strip()\n            ur_line = ur_line.strip()\n            if en_line and ur_line:\n                en_norm = normalize_english(en_line)\n                ur_norm = normalize_urdu(ur_line)\n                if en_norm and ur_norm:\n                    tgt_out.write(en_norm + \"\\n\")  # Roman side\n                    src_out.write(ur_norm + \"\\n\")  # Urdu side\n\n# --- Main normalization driver ---\ndef main():\n    poets = sorted([d for d in os.listdir(BASE_DIR) if os.path.isdir(os.path.join(BASE_DIR, d))])\n    created = 0\n    with open(SRC_FILE, \"w\", encoding=\"utf-8\") as src_out, open(TGT_FILE, \"w\", encoding=\"utf-8\") as tgt_out:\n        for poet in poets:\n            poet_path = os.path.join(BASE_DIR, poet)\n            en_dir = os.path.join(poet_path, \"en\")\n            ur_dir = os.path.join(poet_path, \"ur\")\n            if os.path.isdir(en_dir) and os.path.isdir(ur_dir):\n                en_files = sorted([f for f in os.listdir(en_dir)])\n                ur_files = sorted([f for f in os.listdir(ur_dir)])\n                for enf_name, urf_name in zip(en_files, ur_files):\n                    enf_path = os.path.join(en_dir, enf_name)\n                    urf_path = os.path.join(ur_dir, urf_name)\n                    process_pair_files(enf_path, urf_path, src_out, tgt_out)\n                    created += 1\n    print(f\"✅ Normalization complete. Created '{SRC_FILE}' and '{TGT_FILE}'. Processed {created} file pairs.\")\n\nif __name__ == \"__main__\":\n    main()\n\n# --- Preview first 5 pairs ---\nfor i, (ur, ro) in enumerate(zip(open(SRC_FILE), open(TGT_FILE))):\n    print(\"UR:\", ur.strip())\n    print(\"RO:\", ro.strip())\n    print(\"-\"*50)\n    if i == 4:\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T17:36:13.717173Z","iopub.execute_input":"2025-09-25T17:36:13.717521Z","iopub.status.idle":"2025-09-25T17:36:15.996753Z","shell.execute_reply.started":"2025-09-25T17:36:13.717502Z","shell.execute_reply":"2025-09-25T17:36:15.995814Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'urdu_ghazals_rekhta'...\nremote: Enumerating objects: 112, done.\u001b[K\nremote: Counting objects: 100% (9/9), done.\u001b[K\nremote: Compressing objects: 100% (3/3), done.\u001b[K\nremote: Total 112 (delta 7), reused 6 (delta 6), pack-reused 103 (from 1)\u001b[K\nReceiving objects: 100% (112/112), 2.03 MiB | 10.57 MiB/s, done.\nResolving deltas: 100% (51/51), done.\n✅ Normalization complete. Created '/kaggle/working/urdu.txt' and '/kaggle/working/roman.txt'. Processed 1314 file pairs.\nUR: آنکھ سے دور نہ ہو دل سے اتر جائے گا\nRO: aankh se duur na ho dil se utar jaega\n--------------------------------------------------\nUR: وقت کا کیا ہے گزرتا ہے گزر جائے گا\nRO: vaqt ka kya hai guzarta hai guzar jaega\n--------------------------------------------------\nUR: اتنا مانوس نہ ہو خلوت غم سے اپنی\nRO: itna manus na ho khalvat-e-gham se apni\n--------------------------------------------------\nUR: تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا\nRO: tu kabhi khud ko bhi dekhega to dar jaega\n--------------------------------------------------\nUR: ڈوبتے ڈوبتے کشتی کو اچھالا دے دوں\nRO: dubte dubte kashti ko uchhala de duun\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import re\nimport pickle\nfrom collections import defaultdict, Counter\nfrom typing import List, Dict, Tuple, Set\nimport json\n\nclass UrduRomanBPE:\n    def __init__(self, vocab_size: int = 10000):\n        self.vocab_size = vocab_size\n        self.urdu_vocab = {}\n        self.roman_vocab = {}\n        self.urdu_merges = []\n        self.roman_merges = []\n        self.urdu_word_freqs = defaultdict(int)\n        self.roman_word_freqs = defaultdict(int)\n        \n        # Special tokens\n        self.special_tokens = ['<PAD>', '<UNK>', '<SOS>', '<EOS>']\n        \n    def _get_word_tokens(self, word: str) -> List[str]:\n        \"\"\"Split word into characters with end-of-word marker\"\"\"\n        return list(word) + ['</w>']\n    \n    def _get_pairs(self, word_tokens: List[str]) -> Set[Tuple[str, str]]:\n        \"\"\"Get all pairs of consecutive tokens in word\"\"\"\n        pairs = set()\n        prev_char = word_tokens[0]\n        for char in word_tokens[1:]:\n            pairs.add((prev_char, char))\n            prev_char = char\n        return pairs\n    \n    def _merge_vocab(self, pair: Tuple[str, str], word_freqs: Dict[List[str], int]) -> Dict[List[str], int]:\n        \"\"\"Merge the most frequent pair in vocabulary\"\"\"\n        new_word_freqs = {}\n        bigram = re.escape(' '.join(pair))\n        p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n        \n        for word_tokens in word_freqs:\n            word_str = ' '.join(word_tokens)\n            new_word_str = p.sub(''.join(pair), word_str)\n            new_word_tokens = new_word_str.split()\n            new_word_freqs[tuple(new_word_tokens)] = word_freqs[word_tokens]\n        \n        return new_word_freqs\n    \n    def _build_bpe(self, word_freqs: Dict[str, int], target_vocab_size: int) -> Tuple[Dict, List]:\n        \"\"\"Build BPE vocabulary and merges\"\"\"\n        # Initialize vocabulary with character-level tokens\n        vocab = set()\n        word_token_freqs = {}\n        \n        for word, freq in word_freqs.items():\n            word_tokens = self._get_word_tokens(word)\n            word_token_freqs[tuple(word_tokens)] = freq\n            for token in word_tokens:\n                vocab.add(token)\n        \n        # Add special tokens\n        for token in self.special_tokens:\n            vocab.add(token)\n        \n        merges = []\n        \n        # Iteratively merge most frequent pairs\n        while len(vocab) < target_vocab_size:\n            # Get all pairs and their frequencies\n            pairs = defaultdict(int)\n            for word_tokens, freq in word_token_freqs.items():\n                word_pairs = self._get_pairs(list(word_tokens))\n                for pair in word_pairs:\n                    pairs[pair] += freq\n            \n            if not pairs:\n                break\n            \n            # Find most frequent pair\n            best_pair = max(pairs, key=pairs.get)\n            \n            # Merge the pair\n            word_token_freqs = self._merge_vocab(best_pair, word_token_freqs)\n            merges.append(best_pair)\n            vocab.add(''.join(best_pair))\n        \n        # Create vocabulary mapping\n        vocab_dict = {token: idx for idx, token in enumerate(sorted(vocab))}\n        \n        return vocab_dict, merges\n    \n    def _preprocess_urdu_text(self, text: str) -> str:\n        \"\"\"Preprocess Urdu text\"\"\"\n        # Remove extra whitespaces and normalize\n        text = re.sub(r'\\s+', ' ', text.strip())\n        # Remove punctuation except for sentence boundaries\n        text = re.sub(r'[۔؟!]', ' <EOS> ', text)\n        text = re.sub(r'[،؍]', ' ', text)  # Remove commas and other punctuation\n        return text.strip()\n    \n    def _preprocess_roman_text(self, text: str) -> str:\n        \"\"\"Preprocess Roman Urdu text\"\"\"\n        # Convert to lowercase and remove extra whitespaces\n        text = text.lower().strip()\n        text = re.sub(r'\\s+', ' ', text)\n        # Handle punctuation\n        text = re.sub(r'[.!?]', ' <EOS> ', text)\n        text = re.sub(r'[,;:]', ' ', text)\n        return text.strip()\n    \n    def load_data(self, urdu_file: str, roman_file: str):\n        \"\"\"Load and preprocess data from files\"\"\"\n        print(\"Loading data...\")\n        \n        try:\n            with open(urdu_file, 'r', encoding='utf-8') as f:\n                urdu_lines = f.readlines()\n            \n            with open(roman_file, 'r', encoding='utf-8') as f:\n                roman_lines = f.readlines()\n            \n            print(f\"Loaded {len(urdu_lines)} Urdu sentences and {len(roman_lines)} Roman sentences\")\n            \n            # Process Urdu text\n            for line in urdu_lines:\n                line = self._preprocess_urdu_text(line)\n                if line:\n                    words = line.split()\n                    for word in words:\n                        if word not in self.special_tokens:\n                            self.urdu_word_freqs[word] += 1\n            \n            # Process Roman text\n            for line in roman_lines:\n                line = self._preprocess_roman_text(line)\n                if line:\n                    words = line.split()\n                    for word in words:\n                        if word not in self.special_tokens:\n                            self.roman_word_freqs[word] += 1\n            \n            print(f\"Urdu vocabulary size: {len(self.urdu_word_freqs)}\")\n            print(f\"Roman vocabulary size: {len(self.roman_word_freqs)}\")\n            \n        except FileNotFoundError as e:\n            print(f\"Error: File not found - {e}\")\n            print(\"Please make sure the files exist at the specified paths.\")\n        except Exception as e:\n            print(f\"Error loading data: {e}\")\n    \n    def train(self):\n        \"\"\"Train BPE models for both Urdu and Roman Urdu\"\"\"\n        print(\"Training BPE models...\")\n        \n        # Train Urdu BPE\n        print(\"Training Urdu BPE...\")\n        self.urdu_vocab, self.urdu_merges = self._build_bpe(\n            self.urdu_word_freqs, \n            self.vocab_size // 2\n        )\n        \n        # Train Roman Urdu BPE\n        print(\"Training Roman Urdu BPE...\")\n        self.roman_vocab, self.roman_merges = self._build_bpe(\n            self.roman_word_freqs, \n            self.vocab_size // 2\n        )\n        \n        print(f\"Urdu BPE vocabulary size: {len(self.urdu_vocab)}\")\n        print(f\"Roman BPE vocabulary size: {len(self.roman_vocab)}\")\n        print(f\"Urdu merges: {len(self.urdu_merges)}\")\n        print(f\"Roman merges: {len(self.roman_merges)}\")\n    \n    def _apply_bpe(self, word: str, vocab: Dict, merges: List) -> List[str]:\n        \"\"\"Apply BPE encoding to a word\"\"\"\n        if not word:\n            return []\n        \n        word_tokens = self._get_word_tokens(word)\n        \n        if len(word_tokens) == 1:\n            return word_tokens\n        \n        for merge in merges:\n            if len(word_tokens) == 1:\n                break\n            \n            new_word_tokens = []\n            i = 0\n            \n            while i < len(word_tokens):\n                if (i < len(word_tokens) - 1 and \n                    word_tokens[i] == merge[0] and \n                    word_tokens[i + 1] == merge[1]):\n                    new_word_tokens.append(''.join(merge))\n                    i += 2\n                else:\n                    new_word_tokens.append(word_tokens[i])\n                    i += 1\n            \n            word_tokens = new_word_tokens\n        \n        return word_tokens\n    \n    def encode_urdu(self, text: str) -> List[int]:\n        \"\"\"Encode Urdu text using trained BPE\"\"\"\n        text = self._preprocess_urdu_text(text)\n        tokens = []\n        \n        for word in text.split():\n            if word in self.special_tokens:\n                tokens.append(self.urdu_vocab.get(word, self.urdu_vocab['<UNK>']))\n            else:\n                bpe_tokens = self._apply_bpe(word, self.urdu_vocab, self.urdu_merges)\n                for token in bpe_tokens:\n                    tokens.append(self.urdu_vocab.get(token, self.urdu_vocab['<UNK>']))\n        \n        return tokens\n    \n    def encode_roman(self, text: str) -> List[int]:\n        \"\"\"Encode Roman Urdu text using trained BPE\"\"\"\n        text = self._preprocess_roman_text(text)\n        tokens = []\n        \n        for word in text.split():\n            if word in self.special_tokens:\n                tokens.append(self.roman_vocab.get(word, self.roman_vocab['<UNK>']))\n            else:\n                bpe_tokens = self._apply_bpe(word, self.roman_vocab, self.roman_merges)\n                for token in bpe_tokens:\n                    tokens.append(self.roman_vocab.get(token, self.roman_vocab['<UNK>']))\n        \n        return tokens\n    \n    def decode_urdu(self, token_ids: List[int]) -> str:\n        \"\"\"Decode Urdu token IDs back to text\"\"\"\n        id_to_token = {idx: token for token, idx in self.urdu_vocab.items()}\n        tokens = [id_to_token.get(token_id, '<UNK>') for token_id in token_ids]\n        \n        # Merge tokens and remove end-of-word markers\n        text = ''.join(tokens).replace('</w>', ' ')\n        return text.strip()\n    \n    def decode_roman(self, token_ids: List[int]) -> str:\n        \"\"\"Decode Roman Urdu token IDs back to text\"\"\"\n        id_to_token = {idx: token for token, idx in self.roman_vocab.items()}\n        tokens = [id_to_token.get(token_id, '<UNK>') for token_id in token_ids]\n        \n        # Merge tokens and remove end-of-word markers\n        text = ''.join(tokens).replace('</w>', ' ')\n        return text.strip()\n    \n    def save_model(self, filepath: str):\n        \"\"\"Save trained BPE model\"\"\"\n        model_data = {\n            'urdu_vocab': self.urdu_vocab,\n            'roman_vocab': self.roman_vocab,\n            'urdu_merges': self.urdu_merges,\n            'roman_merges': self.roman_merges,\n            'vocab_size': self.vocab_size,\n            'special_tokens': self.special_tokens\n        }\n        \n        with open(filepath, 'wb') as f:\n            pickle.dump(model_data, f)\n        print(f\"Model saved to {filepath}\")\n    \n    def load_model(self, filepath: str):\n        \"\"\"Load trained BPE model\"\"\"\n        with open(filepath, 'rb') as f:\n            model_data = pickle.load(f)\n        \n        self.urdu_vocab = model_data['urdu_vocab']\n        self.roman_vocab = model_data['roman_vocab']\n        self.urdu_merges = model_data['urdu_merges']\n        self.roman_merges = model_data['roman_merges']\n        self.vocab_size = model_data['vocab_size']\n        self.special_tokens = model_data['special_tokens']\n        print(f\"Model loaded from {filepath}\")\n\n# Usage example and training script\ndef main():\n    # Initialize BPE with desired vocabulary size\n    bpe = UrduRomanBPE(vocab_size=8000)\n    \n    # Load your data\n    bpe.load_data('/kaggle/working/urdu.txt', '/kaggle/working/roman.txt')\n    \n    # Train BPE models\n    bpe.train()\n    \n    # Save the trained model\n    bpe.save_model('/kaggle/working/bpe_model.pkl')\n    \n    # Test with your example\n    urdu_text = \"تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا\"\n    roman_text = \"tu kabhi khud ko bhi dekhega to dar jaega\"\n    \n    print(\"\\n=== Testing BPE Encoding ===\")\n    print(f\"Original Urdu: {urdu_text}\")\n    urdu_encoded = bpe.encode_urdu(urdu_text)\n    print(f\"Urdu Encoded: {urdu_encoded}\")\n    urdu_decoded = bpe.decode_urdu(urdu_encoded)\n    print(f\"Urdu Decoded: {urdu_decoded}\")\n    \n    print(f\"\\nOriginal Roman: {roman_text}\")\n    roman_encoded = bpe.encode_roman(roman_text)\n    print(f\"Roman Encoded: {roman_encoded}\")\n    roman_decoded = bpe.decode_roman(roman_encoded)\n    print(f\"Roman Decoded: {roman_decoded}\")\n    \n    # Print some vocabulary statistics\n    print(f\"\\n=== Vocabulary Statistics ===\")\n    print(f\"Urdu vocabulary size: {len(bpe.urdu_vocab)}\")\n    print(f\"Roman vocabulary size: {len(bpe.roman_vocab)}\")\n    \n    # Show some example tokens\n    print(f\"\\nSample Urdu tokens:\")\n    for i, (token, idx) in enumerate(list(bpe.urdu_vocab.items())[:10]):\n        print(f\"  {token}: {idx}\")\n    \n    print(f\"\\nSample Roman tokens:\")\n    for i, (token, idx) in enumerate(list(bpe.roman_vocab.items())[:10]):\n        print(f\"  {token}: {idx}\")\n\nif __name__ == \"__main__\":\n    main()\n\n# Additional utility functions for integration with your BiLSTM model\nclass DataProcessor:\n    def __init__(self, bpe_model: UrduRomanBPE):\n        self.bpe = bpe_model\n    \n    def prepare_training_data(self, urdu_file: str, roman_file: str, max_len: int = 50):\n        \"\"\"Prepare tokenized data for BiLSTM training\"\"\"\n        urdu_sequences = []\n        roman_sequences = []\n        \n        with open(urdu_file, 'r', encoding='utf-8') as f:\n            urdu_lines = f.readlines()\n        \n        with open(roman_file, 'r', encoding='utf-8') as f:\n            roman_lines = f.readlines()\n        \n        for urdu_line, roman_line in zip(urdu_lines, roman_lines):\n            # Encode sequences\n            urdu_seq = self.bpe.encode_urdu(urdu_line.strip())\n            roman_seq = self.bpe.encode_roman(roman_line.strip())\n            \n            # Add SOS and EOS tokens\n            urdu_seq = [self.bpe.urdu_vocab['<SOS>']] + urdu_seq + [self.bpe.urdu_vocab['<EOS>']]\n            roman_seq = [self.bpe.roman_vocab['<SOS>']] + roman_seq + [self.bpe.roman_vocab['<EOS>']]\n            \n            # Truncate or pad sequences\n            if len(urdu_seq) <= max_len and len(roman_seq) <= max_len:\n                # Pad sequences\n                while len(urdu_seq) < max_len:\n                    urdu_seq.append(self.bpe.urdu_vocab['<PAD>'])\n                while len(roman_seq) < max_len:\n                    roman_seq.append(self.bpe.roman_vocab['<PAD>'])\n                \n                urdu_sequences.append(urdu_seq)\n                roman_sequences.append(roman_seq)\n        \n        return urdu_sequences, roman_sequences\n    \n    def get_vocab_sizes(self):\n        \"\"\"Get vocabulary sizes for model initialization\"\"\"\n        return len(self.bpe.urdu_vocab), len(self.bpe.roman_vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T17:36:15.998164Z","iopub.execute_input":"2025-09-25T17:36:15.998466Z","iopub.status.idle":"2025-09-25T17:41:18.653352Z","shell.execute_reply.started":"2025-09-25T17:36:15.998438Z","shell.execute_reply":"2025-09-25T17:41:18.652690Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nLoaded 21003 Urdu sentences and 21003 Roman sentences\nUrdu vocabulary size: 10302\nRoman vocabulary size: 16889\nTraining BPE models...\nTraining Urdu BPE...\nTraining Roman Urdu BPE...\nUrdu BPE vocabulary size: 4000\nRoman BPE vocabulary size: 4000\nUrdu merges: 3943\nRoman merges: 3968\nModel saved to /kaggle/working/bpe_model.pkl\n\n=== Testing BPE Encoding ===\nOriginal Urdu: تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا\nUrdu Encoded: [803, 3549, 1210, 3636, 642, 1412, 3734, 803, 3485, 880, 3734]\nUrdu Decoded: تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا\n\nOriginal Roman: tu kabhi khud ko bhi dekhega to dar jaega\nRoman Encoded: [3635, 1703, 1908, 1979, 524, 797, 938, 3627, 754, 1556]\nRoman Decoded: tu kabhi khud ko bhi dekhega to dar jaega\n\n=== Vocabulary Statistics ===\nUrdu vocabulary size: 4000\nRoman vocabulary size: 4000\n\nSample Urdu tokens:\n  ': 0\n  </w>: 1\n  <EOS>: 2\n  <PAD>: 3\n  <SOS>: 4\n  <UNK>: 5\n  ء: 6\n  آ: 7\n  آ</w>: 8\n  آؤ</w>: 9\n\nSample Roman tokens:\n  -: 0\n  -ba-: 1\n  -e-: 2\n  -e-a: 3\n  -e-adam</w>: 4\n  -e-af: 5\n  -e-aina</w>: 6\n  -e-alam</w>: 7\n  -e-as: 8\n  -e-ash: 9\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport numpy as np\nimport random\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nimport pickle\nfrom typing import List, Tuple, Optional, Dict, Set\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport re\nfrom collections import defaultdict, Counter\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\n# ========================= BPE IMPLEMENTATION =========================\n\nclass UrduRomanBPE:\n    def __init__(self, vocab_size: int = 10000):\n        self.vocab_size = vocab_size\n        self.urdu_vocab = {}\n        self.roman_vocab = {}\n        self.urdu_merges = []\n        self.roman_merges = []\n        self.urdu_word_freqs = defaultdict(int)\n        self.roman_word_freqs = defaultdict(int)\n        \n        # Special tokens\n        self.special_tokens = ['<PAD>', '<UNK>', '<SOS>', '<EOS>']\n        \n    def _get_word_tokens(self, word: str) -> List[str]:\n        \"\"\"Split word into characters with end-of-word marker\"\"\"\n        return list(word) + ['</w>']\n    \n    def _get_pairs(self, word_tokens: List[str]) -> Set[Tuple[str, str]]:\n        \"\"\"Get all pairs of consecutive tokens in word\"\"\"\n        pairs = set()\n        prev_char = word_tokens[0]\n        for char in word_tokens[1:]:\n            pairs.add((prev_char, char))\n            prev_char = char\n        return pairs\n    \n    def _merge_vocab(self, pair: Tuple[str, str], word_freqs: Dict[List[str], int]) -> Dict[List[str], int]:\n        \"\"\"Merge the most frequent pair in vocabulary\"\"\"\n        new_word_freqs = {}\n        bigram = re.escape(' '.join(pair))\n        p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n        \n        for word_tokens in word_freqs:\n            word_str = ' '.join(word_tokens)\n            new_word_str = p.sub(''.join(pair), word_str)\n            new_word_tokens = new_word_str.split()\n            new_word_freqs[tuple(new_word_tokens)] = word_freqs[word_tokens]\n        \n        return new_word_freqs\n    \n    def _build_bpe(self, word_freqs: Dict[str, int], target_vocab_size: int) -> Tuple[Dict, List]:\n        \"\"\"Build BPE vocabulary and merges\"\"\"\n        # Initialize vocabulary with character-level tokens\n        vocab = set()\n        word_token_freqs = {}\n        \n        for word, freq in word_freqs.items():\n            word_tokens = self._get_word_tokens(word)\n            word_token_freqs[tuple(word_tokens)] = freq\n            for token in word_tokens:\n                vocab.add(token)\n        \n        # Add special tokens\n        for token in self.special_tokens:\n            vocab.add(token)\n        \n        merges = []\n        \n        # Iteratively merge most frequent pairs\n        while len(vocab) < target_vocab_size:\n            # Get all pairs and their frequencies\n            pairs = defaultdict(int)\n            for word_tokens, freq in word_token_freqs.items():\n                word_pairs = self._get_pairs(list(word_tokens))\n                for pair in word_pairs:\n                    pairs[pair] += freq\n            \n            if not pairs:\n                break\n            \n            # Find most frequent pair\n            best_pair = max(pairs, key=pairs.get)\n            \n            # Merge the pair\n            word_token_freqs = self._merge_vocab(best_pair, word_token_freqs)\n            merges.append(best_pair)\n            vocab.add(''.join(best_pair))\n        \n        # Create vocabulary mapping\n        vocab_dict = {token: idx for idx, token in enumerate(sorted(vocab))}\n        \n        return vocab_dict, merges\n    \n    def _preprocess_urdu_text(self, text: str) -> str:\n        \"\"\"Preprocess Urdu text\"\"\"\n        # Remove extra whitespaces and normalize\n        text = re.sub(r'\\s+', ' ', text.strip())\n        # Remove punctuation except for sentence boundaries\n        text = re.sub(r'[۔؟!]', ' <EOS> ', text)\n        text = re.sub(r'[،؍]', ' ', text)  # Remove commas and other punctuation\n        return text.strip()\n    \n    def _preprocess_roman_text(self, text: str) -> str:\n        \"\"\"Preprocess Roman Urdu text\"\"\"\n        # Convert to lowercase and remove extra whitespaces\n        text = text.lower().strip()\n        text = re.sub(r'\\s+', ' ', text)\n        # Handle punctuation\n        text = re.sub(r'[.!?]', ' <EOS> ', text)\n        text = re.sub(r'[,;:]', ' ', text)\n        return text.strip()\n    \n    def load_data(self, urdu_file: str, roman_file: str):\n        \"\"\"Load and preprocess data from files\"\"\"\n        print(\"Loading data...\")\n        \n        try:\n            with open(urdu_file, 'r', encoding='utf-8') as f:\n                urdu_lines = f.readlines()\n            \n            with open(roman_file, 'r', encoding='utf-8') as f:\n                roman_lines = f.readlines()\n            \n            print(f\"Loaded {len(urdu_lines)} Urdu sentences and {len(roman_lines)} Roman sentences\")\n            \n            # Process Urdu text\n            for line in urdu_lines:\n                line = self._preprocess_urdu_text(line)\n                if line:\n                    words = line.split()\n                    for word in words:\n                        if word not in self.special_tokens:\n                            self.urdu_word_freqs[word] += 1\n            \n            # Process Roman text\n            for line in roman_lines:\n                line = self._preprocess_roman_text(line)\n                if line:\n                    words = line.split()\n                    for word in words:\n                        if word not in self.special_tokens:\n                            self.roman_word_freqs[word] += 1\n            \n            print(f\"Urdu vocabulary size: {len(self.urdu_word_freqs)}\")\n            print(f\"Roman vocabulary size: {len(self.roman_word_freqs)}\")\n            \n        except FileNotFoundError as e:\n            print(f\"Error: File not found - {e}\")\n            print(\"Please make sure the files exist at the specified paths.\")\n            raise\n        except Exception as e:\n            print(f\"Error loading data: {e}\")\n            raise\n    \n    def train(self):\n        \"\"\"Train BPE models for both Urdu and Roman Urdu\"\"\"\n        print(\"Training BPE models...\")\n        \n        # Train Urdu BPE\n        print(\"Training Urdu BPE...\")\n        self.urdu_vocab, self.urdu_merges = self._build_bpe(\n            self.urdu_word_freqs, \n            self.vocab_size // 2\n        )\n        \n        # Train Roman Urdu BPE\n        print(\"Training Roman Urdu BPE...\")\n        self.roman_vocab, self.roman_merges = self._build_bpe(\n            self.roman_word_freqs, \n            self.vocab_size // 2\n        )\n        \n        print(f\"Urdu BPE vocabulary size: {len(self.urdu_vocab)}\")\n        print(f\"Roman BPE vocabulary size: {len(self.roman_vocab)}\")\n        print(f\"Urdu merges: {len(self.urdu_merges)}\")\n        print(f\"Roman merges: {len(self.roman_merges)}\")\n    \n    def _apply_bpe(self, word: str, vocab: Dict, merges: List) -> List[str]:\n        \"\"\"Apply BPE encoding to a word\"\"\"\n        if not word:\n            return []\n        \n        word_tokens = self._get_word_tokens(word)\n        \n        if len(word_tokens) == 1:\n            return word_tokens\n        \n        for merge in merges:\n            if len(word_tokens) == 1:\n                break\n            \n            new_word_tokens = []\n            i = 0\n            \n            while i < len(word_tokens):\n                if (i < len(word_tokens) - 1 and \n                    word_tokens[i] == merge[0] and \n                    word_tokens[i + 1] == merge[1]):\n                    new_word_tokens.append(''.join(merge))\n                    i += 2\n                else:\n                    new_word_tokens.append(word_tokens[i])\n                    i += 1\n            \n            word_tokens = new_word_tokens\n        \n        return word_tokens\n    \n    def encode_urdu(self, text: str) -> List[int]:\n        \"\"\"Encode Urdu text using trained BPE\"\"\"\n        text = self._preprocess_urdu_text(text)\n        tokens = []\n        \n        for word in text.split():\n            if word in self.special_tokens:\n                tokens.append(self.urdu_vocab.get(word, self.urdu_vocab['<UNK>']))\n            else:\n                bpe_tokens = self._apply_bpe(word, self.urdu_vocab, self.urdu_merges)\n                for token in bpe_tokens:\n                    tokens.append(self.urdu_vocab.get(token, self.urdu_vocab['<UNK>']))\n        \n        return tokens\n    \n    def encode_roman(self, text: str) -> List[int]:\n        \"\"\"Encode Roman Urdu text using trained BPE\"\"\"\n        text = self._preprocess_roman_text(text)\n        tokens = []\n        \n        for word in text.split():\n            if word in self.special_tokens:\n                tokens.append(self.roman_vocab.get(word, self.roman_vocab['<UNK>']))\n            else:\n                bpe_tokens = self._apply_bpe(word, self.roman_vocab, self.roman_merges)\n                for token in bpe_tokens:\n                    tokens.append(self.roman_vocab.get(token, self.roman_vocab['<UNK>']))\n        \n        return tokens\n    \n    def decode_urdu(self, token_ids: List[int]) -> str:\n        \"\"\"Decode Urdu token IDs back to text\"\"\"\n        id_to_token = {idx: token for token, idx in self.urdu_vocab.items()}\n        tokens = [id_to_token.get(token_id, '<UNK>') for token_id in token_ids]\n        \n        # Merge tokens and remove end-of-word markers\n        text = ''.join(tokens).replace('</w>', ' ')\n        return text.strip()\n    \n    def decode_roman(self, token_ids: List[int]) -> str:\n        \"\"\"Decode Roman Urdu token IDs back to text\"\"\"\n        id_to_token = {idx: token for token, idx in self.roman_vocab.items()}\n        tokens = [id_to_token.get(token_id, '<UNK>') for token_id in token_ids]\n        \n        # Merge tokens and remove end-of-word markers\n        text = ''.join(tokens).replace('</w>', ' ')\n        return text.strip()\n    \n    def save_model(self, filepath: str):\n        \"\"\"Save trained BPE model\"\"\"\n        model_data = {\n            'urdu_vocab': self.urdu_vocab,\n            'roman_vocab': self.roman_vocab,\n            'urdu_merges': self.urdu_merges,\n            'roman_merges': self.roman_merges,\n            'vocab_size': self.vocab_size,\n            'special_tokens': self.special_tokens\n        }\n        \n        with open(filepath, 'wb') as f:\n            pickle.dump(model_data, f)\n        print(f\"Model saved to {filepath}\")\n    \n    def load_model(self, filepath: str):\n        \"\"\"Load trained BPE model\"\"\"\n        with open(filepath, 'rb') as f:\n            model_data = pickle.load(f)\n        \n        self.urdu_vocab = model_data['urdu_vocab']\n        self.roman_vocab = model_data['roman_vocab']\n        self.urdu_merges = model_data['urdu_merges']\n        self.roman_merges = model_data['roman_merges']\n        self.vocab_size = model_data['vocab_size']\n        self.special_tokens = model_data['special_tokens']\n        print(f\"Model loaded from {filepath}\")\n\n\nclass DataProcessor:\n    def __init__(self, bpe_model: UrduRomanBPE):\n        self.bpe = bpe_model\n    \n    def prepare_training_data(self, urdu_file: str, roman_file: str, max_len: int = 50):\n        \"\"\"Prepare tokenized data for BiLSTM training\"\"\"\n        urdu_sequences = []\n        roman_sequences = []\n        \n        with open(urdu_file, 'r', encoding='utf-8') as f:\n            urdu_lines = f.readlines()\n        \n        with open(roman_file, 'r', encoding='utf-8') as f:\n            roman_lines = f.readlines()\n        \n        for urdu_line, roman_line in zip(urdu_lines, roman_lines):\n            # Encode sequences\n            urdu_seq = self.bpe.encode_urdu(urdu_line.strip())\n            roman_seq = self.bpe.encode_roman(roman_line.strip())\n            \n            # Add SOS and EOS tokens\n            urdu_seq = [self.bpe.urdu_vocab['<SOS>']] + urdu_seq + [self.bpe.urdu_vocab['<EOS>']]\n            roman_seq = [self.bpe.roman_vocab['<SOS>']] + roman_seq + [self.bpe.roman_vocab['<EOS>']]\n            \n            # Truncate or pad sequences\n            if len(urdu_seq) <= max_len and len(roman_seq) <= max_len:\n                # Pad sequences\n                while len(urdu_seq) < max_len:\n                    urdu_seq.append(self.bpe.urdu_vocab['<PAD>'])\n                while len(roman_seq) < max_len:\n                    roman_seq.append(self.bpe.roman_vocab['<PAD>'])\n                \n                urdu_sequences.append(urdu_seq)\n                roman_sequences.append(roman_seq)\n        \n        return urdu_sequences, roman_sequences\n    \n    def get_vocab_sizes(self):\n        \"\"\"Get vocabulary sizes for model initialization\"\"\"\n        return len(self.bpe.urdu_vocab), len(self.bpe.roman_vocab)\n\n# ========================= NEURAL NETWORK MODELS =========================\n\nclass BiLSTMEncoder(nn.Module):\n    \"\"\"BiLSTM Encoder with 2 layers\"\"\"\n    \n    def __init__(self, vocab_size: int, embedding_dim: int, hidden_dim: int, \n                 num_layers: int = 2, dropout: float = 0.3):\n        super(BiLSTMEncoder, self).__init__()\n        \n        self.vocab_size = vocab_size\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        \n        # Embedding layer\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        \n        # BiLSTM layers\n        self.bilstm = nn.LSTM(\n            input_size=embedding_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            bidirectional=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        \n        # Dropout layer\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x: torch.Tensor, lengths: Optional[torch.Tensor] = None):\n        \"\"\"\n        Args:\n            x: Input tensor of shape (batch_size, seq_len)\n            lengths: Actual lengths of sequences (for packing)\n        \n        Returns:\n            outputs: BiLSTM outputs (batch_size, seq_len, hidden_dim * 2)\n            hidden: Final hidden state (num_layers * 2, batch_size, hidden_dim)\n            cell: Final cell state (num_layers * 2, batch_size, hidden_dim)\n        \"\"\"\n        batch_size = x.size(0)\n        \n        # Embedding\n        embedded = self.embedding(x)  # (batch_size, seq_len, embedding_dim)\n        embedded = self.dropout(embedded)\n        \n        # Pack sequence if lengths are provided\n        if lengths is not None:\n            embedded = nn.utils.rnn.pack_padded_sequence(\n                embedded, lengths.cpu(), batch_first=True, enforce_sorted=False\n            )\n        \n        # BiLSTM forward pass\n        outputs, (hidden, cell) = self.bilstm(embedded)\n        \n        # Unpack if packed\n        if lengths is not None:\n            outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n        \n        return outputs, hidden, cell\n\n\nclass LSTMDecoder(nn.Module):\n    \"\"\"LSTM Decoder with 4 layers \"\"\"\n    \n    def __init__(self, vocab_size: int, embedding_dim: int, hidden_dim: int, \n                 encoder_hidden_dim: int, num_layers: int = 4, dropout: float = 0.3):\n        super(LSTMDecoder, self).__init__()\n        \n        self.vocab_size = vocab_size\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = hidden_dim\n        self.encoder_hidden_dim = encoder_hidden_dim\n        self.num_layers = num_layers\n        \n        # Embedding layer\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        \n        # LSTM layers\n        self.lstm = nn.LSTM(\n            input_size=embedding_dim + encoder_hidden_dim * 2,  # +context from attention\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        \n        self.attention = nn.Linear(hidden_dim + encoder_hidden_dim * 2, encoder_hidden_dim * 2)\n        \n        # Output projection\n        self.out_projection = nn.Linear(\n            hidden_dim + encoder_hidden_dim * 2, vocab_size\n        )\n        \n        # Dropout\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x: torch.Tensor, hidden: torch.Tensor, cell: torch.Tensor,\n                encoder_outputs: torch.Tensor, mask: Optional[torch.Tensor] = None):\n        \"\"\"\n        Args:\n            x: Input token (batch_size, 1)\n            hidden: Previous hidden state (num_layers, batch_size, hidden_dim)\n            cell: Previous cell state (num_layers, batch_size, hidden_dim)\n            encoder_outputs: Encoder outputs (batch_size, enc_seq_len, enc_hidden_dim * 2)\n            mask: Attention mask (batch_size, enc_seq_len)\n        \n        Returns:\n            output: Output logits (batch_size, vocab_size)\n            hidden: Updated hidden state\n            cell: Updated cell state\n            attention_weights: Attention weights (batch_size, enc_seq_len)\n        \"\"\"\n        batch_size = x.size(0)\n        \n        # Embedding\n        embedded = self.embedding(x)  # (batch_size, 1, embedding_dim)\n        embedded = self.dropout(embedded)\n        \n        # Compute attention\n        # Use top layer hidden state for attention\n        top_hidden = hidden[-1].unsqueeze(1)  # (batch_size, 1, hidden_dim)\n        \n        # Repeat for each encoder position\n        enc_seq_len = encoder_outputs.size(1)\n        top_hidden_repeated = top_hidden.repeat(1, enc_seq_len, 1)  # (batch_size, enc_seq_len, hidden_dim)\n        \n        # Concatenate decoder hidden with encoder outputs\n        attention_input = torch.cat([top_hidden_repeated, encoder_outputs], dim=2)\n        \n        # Compute attention scores\n        attention_scores = self.attention(attention_input)  # (batch_size, enc_seq_len, enc_hidden_dim * 2)\n        attention_scores = torch.sum(attention_scores * encoder_outputs, dim=2)  # (batch_size, enc_seq_len)\n        \n        # Apply mask if provided\n        if mask is not None:\n            attention_scores.masked_fill_(mask == 0, -1e9)\n        \n        # Softmax to get attention weights\n        attention_weights = F.softmax(attention_scores, dim=1)  # (batch_size, enc_seq_len)\n        \n        # Compute context vector\n        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)  # (batch_size, 1, enc_hidden_dim * 2)\n        \n        # Concatenate embedding with context\n        lstm_input = torch.cat([embedded, context], dim=2)  # (batch_size, 1, embedding_dim + enc_hidden_dim * 2)\n        \n        # LSTM forward pass\n        lstm_out, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n        \n        # Concatenate LSTM output with context for final projection\n        output_input = torch.cat([lstm_out.squeeze(1), context.squeeze(1)], dim=1)\n        output = self.out_projection(output_input)  # (batch_size, vocab_size)\n        \n        return output, hidden, cell, attention_weights.squeeze(1)\n\n\nclass Seq2SeqModel(nn.Module):\n    \"\"\"Complete Seq2Seq model with BiLSTM encoder and LSTM decoder\"\"\"\n    \n    def __init__(self, encoder_vocab_size: int, decoder_vocab_size: int,\n                 embedding_dim: int = 256, encoder_hidden_dim: int = 512,\n                 decoder_hidden_dim: int = 512, encoder_layers: int = 2,\n                 decoder_layers: int = 4, dropout: float = 0.3):\n        super(Seq2SeqModel, self).__init__()\n        \n        self.encoder_vocab_size = encoder_vocab_size\n        self.decoder_vocab_size = decoder_vocab_size\n        self.encoder_hidden_dim = encoder_hidden_dim\n        self.decoder_hidden_dim = decoder_hidden_dim\n        \n        # Encoder (BiLSTM)\n        self.encoder = BiLSTMEncoder(\n            vocab_size=encoder_vocab_size,\n            embedding_dim=embedding_dim,\n            hidden_dim=encoder_hidden_dim,\n            num_layers=encoder_layers,\n            dropout=dropout\n        )\n        \n        # Decoder (LSTM)\n        self.decoder = LSTMDecoder(\n            vocab_size=decoder_vocab_size,\n            embedding_dim=embedding_dim,\n            hidden_dim=decoder_hidden_dim,\n            encoder_hidden_dim=encoder_hidden_dim,\n            num_layers=decoder_layers,\n            dropout=dropout\n        )\n        \n        # Bridge to connect encoder and decoder hidden states\n        self.bridge_hidden = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n        self.bridge_cell = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n        \n    def _bridge_encoder_decoder(self, encoder_hidden: torch.Tensor, encoder_cell: torch.Tensor):\n        \"\"\"Bridge encoder and decoder hidden states\"\"\"\n        # encoder_hidden/cell: (encoder_layers * 2, batch_size, encoder_hidden_dim)\n        batch_size = encoder_hidden.size(1)\n        \n        # Take the last layer's forward and backward hidden states\n        # Forward: encoder_hidden[-2], Backward: encoder_hidden[-1]\n        last_hidden = torch.cat([encoder_hidden[-2], encoder_hidden[-1]], dim=1)  # (batch_size, encoder_hidden_dim * 2)\n        last_cell = torch.cat([encoder_cell[-2], encoder_cell[-1]], dim=1)\n        \n        # Project to decoder dimensions\n        decoder_hidden = self.bridge_hidden(last_hidden)  # (batch_size, decoder_hidden_dim)\n        decoder_cell = self.bridge_cell(last_cell)\n        \n        # Repeat for decoder layers\n        decoder_hidden = decoder_hidden.unsqueeze(0).repeat(self.decoder.num_layers, 1, 1)\n        decoder_cell = decoder_cell.unsqueeze(0).repeat(self.decoder.num_layers, 1, 1)\n        \n        return decoder_hidden, decoder_cell\n    \n    def forward(self, src: torch.Tensor, tgt: torch.Tensor, src_lengths: Optional[torch.Tensor] = None,\n                teacher_forcing_ratio: float = 0.5):\n        \"\"\"\n        Args:\n            src: Source sequences (batch_size, src_seq_len)\n            tgt: Target sequences (batch_size, tgt_seq_len)\n            src_lengths: Source sequence lengths\n            teacher_forcing_ratio: Probability of using teacher forcing\n        \n        Returns:\n            outputs: Decoder outputs (batch_size, tgt_seq_len, vocab_size)\n            attention_weights: Attention weights for visualization\n        \"\"\"\n        batch_size = src.size(0)\n        tgt_seq_len = tgt.size(1)\n        \n        # Encoder forward pass\n        encoder_outputs, encoder_hidden, encoder_cell = self.encoder(src, src_lengths)\n        \n        # Bridge encoder and decoder\n        decoder_hidden, decoder_cell = self._bridge_encoder_decoder(encoder_hidden, encoder_cell)\n        \n        # Create attention mask for source padding\n        if src_lengths is not None:\n            src_mask = torch.zeros(batch_size, src.size(1), device=src.device)\n            for i, length in enumerate(src_lengths):\n                src_mask[i, :length] = 1\n        else:\n            src_mask = (src != 0).float()  # Assume 0 is padding token\n        \n        # Decoder forward pass\n        outputs = []\n        attention_weights = []\n        \n        # Start with SOS token (assuming index 2)\n        decoder_input = tgt[:, 0].unsqueeze(1)  # (batch_size, 1)\n        \n        for t in range(1, tgt_seq_len):\n            # Decoder step\n            output, decoder_hidden, decoder_cell, attn_weights = self.decoder(\n                decoder_input, decoder_hidden, decoder_cell, encoder_outputs, src_mask\n            )\n            \n            outputs.append(output)\n            attention_weights.append(attn_weights)\n            \n            # Teacher forcing\n            if random.random() < teacher_forcing_ratio:\n                decoder_input = tgt[:, t].unsqueeze(1)  # Use ground truth\n            else:\n                decoder_input = output.argmax(dim=1).unsqueeze(1)  # Use prediction\n        \n        outputs = torch.stack(outputs, dim=1)  # (batch_size, tgt_seq_len-1, vocab_size)\n        attention_weights = torch.stack(attention_weights, dim=1)  # (batch_size, tgt_seq_len-1, src_seq_len)\n        \n        return outputs, attention_weights\n    \n    def translate(self, src: torch.Tensor, max_length: int = 50, sos_token: int = 2, \n                  eos_token: int = 3, src_lengths: Optional[torch.Tensor] = None):\n        \"\"\"Translate a source sequence\"\"\"\n        self.eval()\n        \n        with torch.no_grad():\n            batch_size = src.size(0)\n            \n            # Encoder forward pass\n            encoder_outputs, encoder_hidden, encoder_cell = self.encoder(src, src_lengths)\n            \n            # Bridge encoder and decoder\n            decoder_hidden, decoder_cell = self._bridge_encoder_decoder(encoder_hidden, encoder_cell)\n            \n            # Create attention mask\n            if src_lengths is not None:\n                src_mask = torch.zeros(batch_size, src.size(1), device=src.device)\n                for i, length in enumerate(src_lengths):\n                    src_mask[i, :length] = 1\n            else:\n                src_mask = (src != 0).float()\n            \n            # Initialize with SOS token\n            decoder_input = torch.full((batch_size, 1), sos_token, device=src.device)\n            \n            outputs = []\n            attention_weights = []\n            \n            for _ in range(max_length):\n                output, decoder_hidden, decoder_cell, attn_weights = self.decoder(\n                    decoder_input, decoder_hidden, decoder_cell, encoder_outputs, src_mask\n                )\n                \n                predicted = output.argmax(dim=1)\n                outputs.append(predicted)\n                attention_weights.append(attn_weights)\n                \n                decoder_input = predicted.unsqueeze(1)\n                \n                # Stop if all sequences have produced EOS token\n                if (predicted == eos_token).all():\n                    break\n            \n            outputs = torch.stack(outputs, dim=1)  # (batch_size, generated_length)\n            attention_weights = torch.stack(attention_weights, dim=1)\n            \n            return outputs, attention_weights\n\n\n# ========================= DATASET AND TRAINING =========================\n\nclass UrduRomanDataset(Dataset):\n    \"\"\"Dataset class for Urdu-Roman pairs\"\"\"\n    \n    def __init__(self, urdu_sequences: List[List[int]], roman_sequences: List[List[int]]):\n        assert len(urdu_sequences) == len(roman_sequences)\n        self.urdu_sequences = urdu_sequences\n        self.roman_sequences = roman_sequences\n    \n    def __len__(self):\n        return len(self.urdu_sequences)\n    \n    def __getitem__(self, idx):\n        return {\n            'urdu': torch.tensor(self.urdu_sequences[idx], dtype=torch.long),\n            'roman': torch.tensor(self.roman_sequences[idx], dtype=torch.long)\n        }\n\n\ndef collate_fn(batch):\n    \"\"\"Custom collate function for padding sequences\"\"\"\n    urdu_seqs = [item['urdu'] for item in batch]\n    roman_seqs = [item['roman'] for item in batch]\n    \n    # Get lengths before padding\n    urdu_lengths = torch.tensor([len(seq) for seq in urdu_seqs])\n    roman_lengths = torch.tensor([len(seq) for seq in roman_seqs])\n    \n    # Pad sequences\n    urdu_padded = pad_sequence(urdu_seqs, batch_first=True, padding_value=0)\n    roman_padded = pad_sequence(roman_seqs, batch_first=True, padding_value=0)\n    \n    return {\n        'urdu': urdu_padded,\n        'roman': roman_padded,\n        'urdu_lengths': urdu_lengths,\n        'roman_lengths': roman_lengths\n    }\n\n\nclass Trainer:\n    \"\"\"Training class for the seq2seq model (with BLEU, PPL, CER, and qualitative examples)\"\"\"\n    \n    def __init__(self, model, train_dataloader: DataLoader,\n                 val_dataloader: DataLoader, device: torch.device,\n                 roman_bpe=None, urdu_bpe=None):\n        self.model = model\n        self.train_dataloader = train_dataloader\n        self.val_dataloader = val_dataloader\n        self.device = device\n        self.roman_bpe = roman_bpe\n        self.urdu_bpe = urdu_bpe\n        \n        self.model.to(device)\n        \n        # Loss, optimizer, scheduler\n        self.criterion = nn.CrossEntropyLoss(ignore_index=0)\n        self.optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n            self.optimizer, mode='min', factor=0.5, patience=3\n        )\n        \n        # History\n        self.train_losses = []\n        self.val_losses = []\n        self.val_bleus = []\n        self.val_cers = []\n    \n    # -------------------------\n    # Train one epoch\n    # -------------------------\n    def train_epoch(self, epoch: int):\n        self.model.train()\n        total_loss = 0\n        progress_bar = tqdm(self.train_dataloader, desc=f'Epoch {epoch+1}')\n        \n        for batch in progress_bar:\n            urdu = batch['urdu'].to(self.device)\n            roman = batch['roman'].to(self.device)\n            urdu_lengths = batch['urdu_lengths'].to(self.device)\n            \n            self.optimizer.zero_grad()\n            outputs, _ = self.model(urdu, roman, urdu_lengths, teacher_forcing_ratio=0.7)\n            \n            targets = roman[:, 1:].contiguous().view(-1)\n            outputs = outputs.view(-1, outputs.size(-1))\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n            self.optimizer.step()\n            \n            total_loss += loss.item()\n            progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})\n        \n        avg_loss = total_loss / len(self.train_dataloader)\n        self.train_losses.append(avg_loss)\n        return avg_loss\n    \n    # -------------------------\n    # Validation (Loss, BLEU, PPL, CER)\n    # -------------------------\n    def validate(self, max_len=50):\n        self.model.eval()\n        total_loss = 0\n        bleu_scores = []\n        total_ed, total_tokens = 0, 0\n        \n        smoothie = SmoothingFunction().method4\n        \n        with torch.no_grad():\n            for batch in self.val_dataloader:\n                urdu = batch['urdu'].to(self.device)\n                roman = batch['roman'].to(self.device)\n                urdu_lengths = batch['urdu_lengths'].to(self.device)\n                \n                outputs, predictions = self.model(urdu, roman, urdu_lengths, teacher_forcing_ratio=0.0)\n                \n                targets = roman[:, 1:].contiguous().view(-1)\n                outputs = outputs.view(-1, outputs.size(-1))\n                loss = self.criterion(outputs, targets)\n                total_loss += loss.item()\n                \n                if self.roman_bpe is not None:\n                    for j in range(urdu.size(0)):\n                        hyp_tokens = predictions[j].cpu().numpy()\n                        hyp_text = self.roman_bpe.decode(hyp_tokens)\n                        ref_tokens = roman[j].cpu().numpy()\n                        ref_text = self.roman_bpe.decode(ref_tokens)\n                        \n                        bleu = sentence_bleu([ref_text.split()], hyp_text.split(), smoothing_function=smoothie)\n                        bleu_scores.append(bleu)\n                        \n                        total_ed += editdistance.eval(ref_text, hyp_text)\n                        total_tokens += len(ref_text)\n        \n        avg_loss = total_loss / len(self.val_dataloader)\n        avg_bleu = np.mean(bleu_scores) if bleu_scores else 0.0\n        ppl = np.exp(avg_loss)\n        cer = total_ed / total_tokens if total_tokens > 0 else 0.0\n        \n        self.val_losses.append(avg_loss)\n        self.val_bleus.append(avg_bleu)\n        self.val_cers.append(cer)\n        \n        return avg_loss, avg_bleu, ppl, cer\n    \n    # -------------------------\n    # Full training loop\n    # -------------------------\n    def train(self, num_epochs: int):\n        print(f\"Starting training for {num_epochs} epochs...\")\n        \n        best_val_loss = float('inf')\n        patience_counter = 0\n        early_stopping_patience = 10\n        \n        for epoch in range(num_epochs):\n            train_loss = self.train_epoch(epoch)\n            val_loss, val_bleu, val_ppl, val_cer = self.validate()\n            \n            old_lr = self.optimizer.param_groups[0]['lr']\n            self.scheduler.step(val_loss)\n            new_lr = self.optimizer.param_groups[0]['lr']\n            \n            print(f'Epoch {epoch+1}/{num_epochs}:')\n            print(f'  Train Loss: {train_loss:.4f}')\n            print(f'  Val Loss: {val_loss:.4f}')\n            print(f'  Val BLEU: {val_bleu:.4f}')\n            print(f'  Val PPL: {val_ppl:.2f}')\n            print(f'  Val CER: {val_cer:.4f}')\n            print(f'  Learning Rate: {new_lr:.6f}')\n            \n            if old_lr != new_lr:\n                print(f'  Learning rate reduced from {old_lr:.6f} to {new_lr:.6f}')\n            \n            # Save best model\n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                patience_counter = 0\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': self.model.state_dict(),\n                    'optimizer_state_dict': self.optimizer.state_dict(),\n                    'train_losses': self.train_losses,\n                    'val_losses': self.val_losses,\n                    'val_bleus': self.val_bleus,\n                    'val_cers': self.val_cers\n                }, '/kaggle/working/best_model.pt')\n                print(f'  New best model saved!')\n            else:\n                patience_counter += 1\n            \n            if patience_counter >= early_stopping_patience:\n                print(f'Early stopping after {epoch+1} epochs')\n                break\n        \n        print(\"Training completed!\")\n    \n    # -------------------------\n    # Plot training curves\n    # -------------------------\n    def plot_losses(self):\n        plt.figure(figsize=(10, 6))\n        plt.plot(self.train_losses, label='Training Loss')\n        plt.plot(self.val_losses, label='Validation Loss')\n        if self.val_bleus:\n            plt.plot(self.val_bleus, label='Validation BLEU')\n        if self.val_cers:\n            plt.plot(self.val_cers, label='Validation CER')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss / Metric')\n        plt.title('Training Progress')\n        plt.legend()\n        plt.grid(True)\n        plt.show()\n    \n    # -------------------------\n    # Show qualitative examples\n    # -------------------------\n    def evaluate_examples(self, dataloader, num_examples=5, max_len=50):\n        self.model.eval()\n        examples = []\n        \n        with torch.no_grad():\n            for batch in dataloader:\n                urdu = batch['urdu'].to(self.device)\n                roman = batch['roman'].to(self.device)\n                urdu_lengths = batch['urdu_lengths'].to(self.device)\n                \n                _, predictions = self.model(urdu, roman, urdu_lengths, teacher_forcing_ratio=0.0)\n                \n                for i in range(urdu.size(0)):\n                    src_text = self.urdu_bpe.decode(urdu[i].cpu().numpy()) if self.urdu_bpe else \"N/A\"\n                    tgt_text = self.roman_bpe.decode(roman[i].cpu().numpy()) if self.roman_bpe else \"N/A\"\n                    pred_text = self.roman_bpe.decode(predictions[i].cpu().numpy()) if self.roman_bpe else \"N/A\"\n                    \n                    examples.append((src_text, tgt_text, pred_text))\n                    if len(examples) >= num_examples:\n                        break\n                if len(examples) >= num_examples:\n                    break\n        \n        print(\"\\nQualitative Examples:\")\n        print(\"-\" * 60)\n        for src, tgt, pred in examples:\n            print(f\"SRC: {src}\")\n            print(f\"TGT: {tgt}\")\n            print(f\"PRED: {pred}\")\n            print(\"-\" * 60)\n# ========================= MAIN TRAINING FUNCTION =========================\n\ndef main():\n    \"\"\"Main function to train the complete pipeline\"\"\"\n    \n    # Set device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    # Step 1: Train BPE model\n    print(\"=\" * 50)\n    print(\"STEP 1: Training BPE Model\")\n    print(\"=\" * 50)\n    \n    bpe = UrduRomanBPE(vocab_size=8000)\n    \n    try:\n        # Try to load existing BPE model\n        bpe.load_model('/kaggle/working/bpe_model.pkl')\n        print(\"Loaded existing BPE model\")\n    except FileNotFoundError:\n        print(\"Training new BPE model...\")\n        # Train new BPE model\n        bpe.load_data('/kaggle/working/urdu.txt', '/kaggle/working/roman.txt')\n        bpe.train()\n        bpe.save_model('/kaggle/working/bpe_model.pkl')\n    \n    # Test BPE with your example\n    print(\"\\n=== Testing BPE Encoding ===\")\n    urdu_text = \"تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا\"\n    roman_text = \"tu kabhi khud ko bhi dekhega to dar jaega\"\n    \n    print(f\"Original Urdu: {urdu_text}\")\n    urdu_encoded = bpe.encode_urdu(urdu_text)\n    print(f\"Urdu Encoded: {urdu_encoded}\")\n    urdu_decoded = bpe.decode_urdu(urdu_encoded)\n    print(f\"Urdu Decoded: {urdu_decoded}\")\n    \n    print(f\"\\nOriginal Roman: {roman_text}\")\n    roman_encoded = bpe.encode_roman(roman_text)\n    print(f\"Roman Encoded: {roman_encoded}\")\n    roman_decoded = bpe.decode_roman(roman_encoded)\n    print(f\"Roman Decoded: {roman_decoded}\")\n    \n    # Step 2: Prepare training data\n    print(\"\\n\" + \"=\" * 50)\n    print(\"STEP 2: Preparing Training Data\")\n    print(\"=\" * 50)\n    \n    processor = DataProcessor(bpe)\n    urdu_seqs, roman_seqs = processor.prepare_training_data(\n        '/kaggle/working/urdu.txt',\n        '/kaggle/working/roman.txt',\n        max_len=50\n    )\n    \n    print(f\"Prepared {len(urdu_seqs)} sequence pairs\")\n    \n    # Split data\n    split_idx = int(0.8 * len(urdu_seqs))\n    train_urdu, val_urdu = urdu_seqs[:split_idx], urdu_seqs[split_idx:]\n    train_roman, val_roman = roman_seqs[:split_idx], roman_seqs[split_idx:]\n    \n    print(f\"Training samples: {len(train_urdu)}\")\n    print(f\"Validation samples: {len(val_urdu)}\")\n    \n    # Create datasets and dataloaders\n    train_dataset = UrduRomanDataset(train_urdu, train_roman)\n    val_dataset = UrduRomanDataset(val_urdu, val_roman)\n    \n    train_dataloader = DataLoader(\n        train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn\n    )\n    val_dataloader = DataLoader(\n        val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn\n    )\n    \n    # Step 3: Create and train model\n    print(\"\\n\" + \"=\" * 50)\n    print(\"STEP 3: Creating and Training Model\")\n    print(\"=\" * 50)\n    \n    # Get vocabulary sizes\n    encoder_vocab_size, decoder_vocab_size = processor.get_vocab_sizes()\n    print(f\"Encoder vocab size: {encoder_vocab_size}\")\n    print(f\"Decoder vocab size: {decoder_vocab_size}\")\n    \n    # Create model\n    model = Seq2SeqModel(\n        encoder_vocab_size=encoder_vocab_size,\n        decoder_vocab_size=decoder_vocab_size,\n        embedding_dim=256,\n        encoder_hidden_dim=512,\n        decoder_hidden_dim=512,\n        encoder_layers=2,  # BiLSTM with 2 layers\n        decoder_layers=4,  # LSTM with 4 layers\n        dropout=0.3\n    )\n    \n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"Model created with {total_params:,} total parameters\")\n    print(f\"Trainable parameters: {trainable_params:,}\")\n    \n    # Create trainer and train\n    trainer = Trainer(model, train_dataloader, val_dataloader, device)\n    trainer.train(num_epochs=10)\n    \n    # Plot losses\n    trainer.plot_losses()\n    \n    # Step 4: Test translation\n    print(\"\\n\" + \"=\" * 50)\n    print(\"STEP 4: Testing Translation\")\n    print(\"=\" * 50)\n    \n    # Load best model\n    checkpoint = torch.load('/kaggle/working/best_model.pt', map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n    \n    # Test with example\n    test_urdu = \"تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا\"\n    urdu_tokens = bpe.encode_urdu(test_urdu)\n    \n    # Add SOS and EOS tokens\n    urdu_tokens = [bpe.urdu_vocab['<SOS>']] + urdu_tokens + [bpe.urdu_vocab['<EOS>']]\n    urdu_tensor = torch.tensor([urdu_tokens], device=device)\n    \n    with torch.no_grad():\n        translated, attention = model.translate(\n            urdu_tensor, \n            max_length=50,\n            sos_token=bpe.roman_vocab['<SOS>'],\n            eos_token=bpe.roman_vocab['<EOS>']\n        )\n    \n    # Decode translation\n    translated_tokens = translated[0].cpu().tolist()\n    # Remove special tokens for cleaner output\n    clean_tokens = [t for t in translated_tokens if t not in [\n        bpe.roman_vocab['<PAD>'], \n        bpe.roman_vocab['<SOS>'], \n        bpe.roman_vocab['<EOS>']\n    ]]\n    translated_text = bpe.decode_roman(clean_tokens)\n    \n    print(f\"Input Urdu: {test_urdu}\")\n    print(f\"Translated Roman: {translated_text}\")\n    print(f\"Expected Roman: tu kabhi khud ko bhi dekhega to dar jaega\")\n    \n    # Save final model info\n    model_info = {\n        'encoder_vocab_size': encoder_vocab_size,\n        'decoder_vocab_size': decoder_vocab_size,\n        'model_architecture': {\n            'encoder_layers': 2,\n            'decoder_layers': 4,\n            'embedding_dim': 256,\n            'encoder_hidden_dim': 512,\n            'decoder_hidden_dim': 512\n        },\n        'total_parameters': total_params,\n        'training_history': {\n            'train_losses': trainer.train_losses,\n            'val_losses': trainer.val_losses\n        }\n    }\n    \n    with open('/kaggle/working/model_info.pkl', 'wb') as f:\n        pickle.dump(model_info, f)\n    \n    print(f\"\\nModel info saved to /kaggle/working/model_info.pkl\")\n    print(\"Training pipeline completed successfully!\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T17:48:58.196213Z","iopub.execute_input":"2025-09-25T17:48:58.196545Z","iopub.status.idle":"2025-09-25T18:31:36.265867Z","shell.execute_reply.started":"2025-09-25T17:48:58.196521Z","shell.execute_reply":"2025-09-25T18:31:36.264904Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n==================================================\nSTEP 1: Training BPE Model\n==================================================\nModel loaded from /kaggle/working/bpe_model.pkl\nLoaded existing BPE model\n\n=== Testing BPE Encoding ===\nOriginal Urdu: تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا\nUrdu Encoded: [803, 3549, 1210, 3636, 642, 1412, 3734, 803, 3485, 880, 3734]\nUrdu Decoded: تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا\n\nOriginal Roman: tu kabhi khud ko bhi dekhega to dar jaega\nRoman Encoded: [3635, 1703, 1908, 1979, 524, 797, 938, 3627, 754, 1556]\nRoman Decoded: tu kabhi khud ko bhi dekhega to dar jaega\n\n==================================================\nSTEP 2: Preparing Training Data\n==================================================\nPrepared 21003 sequence pairs\nTraining samples: 16802\nValidation samples: 4201\n\n==================================================\nSTEP 3: Creating and Training Model\n==================================================\nEncoder vocab size: 4000\nDecoder vocab size: 4000\nModel created with 30,250,912 total parameters\nTrainable parameters: 30,250,912\nStarting training for 10 epochs...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 526/526 [03:48<00:00,  2.30it/s, Loss=1.5880]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10:\n  Train Loss: 1.4098\n  Val Loss: 1.5491\n  Val BLEU: 0.0000\n  Val PPL: 4.71\n  Val CER: 0.0000\n  Learning Rate: 0.001000\n  New best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 526/526 [03:44<00:00,  2.35it/s, Loss=0.7165]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10:\n  Train Loss: 1.1152\n  Val Loss: 1.0411\n  Val BLEU: 0.0000\n  Val PPL: 2.83\n  Val CER: 0.0000\n  Learning Rate: 0.001000\n  New best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 526/526 [03:43<00:00,  2.36it/s, Loss=0.8848]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10:\n  Train Loss: 0.8670\n  Val Loss: 0.8863\n  Val BLEU: 0.0000\n  Val PPL: 2.43\n  Val CER: 0.0000\n  Learning Rate: 0.001000\n  New best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 526/526 [03:43<00:00,  2.35it/s, Loss=1.0143]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10:\n  Train Loss: 0.6991\n  Val Loss: 0.7729\n  Val BLEU: 0.0000\n  Val PPL: 2.17\n  Val CER: 0.0000\n  Learning Rate: 0.001000\n  New best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 526/526 [03:43<00:00,  2.36it/s, Loss=0.3835]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10:\n  Train Loss: 0.5790\n  Val Loss: 0.7384\n  Val BLEU: 0.0000\n  Val PPL: 2.09\n  Val CER: 0.0000\n  Learning Rate: 0.001000\n  New best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 526/526 [03:43<00:00,  2.35it/s, Loss=0.5002]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10:\n  Train Loss: 0.4974\n  Val Loss: 0.6531\n  Val BLEU: 0.0000\n  Val PPL: 1.92\n  Val CER: 0.0000\n  Learning Rate: 0.001000\n  New best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 526/526 [03:43<00:00,  2.35it/s, Loss=0.1651]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10:\n  Train Loss: 0.4306\n  Val Loss: 0.6025\n  Val BLEU: 0.0000\n  Val PPL: 1.83\n  Val CER: 0.0000\n  Learning Rate: 0.001000\n  New best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 526/526 [03:44<00:00,  2.35it/s, Loss=0.4348]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10:\n  Train Loss: 0.3741\n  Val Loss: 0.5756\n  Val BLEU: 0.0000\n  Val PPL: 1.78\n  Val CER: 0.0000\n  Learning Rate: 0.001000\n  New best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 526/526 [03:44<00:00,  2.34it/s, Loss=0.4279]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10:\n  Train Loss: 0.3476\n  Val Loss: 0.5609\n  Val BLEU: 0.0000\n  Val PPL: 1.75\n  Val CER: 0.0000\n  Learning Rate: 0.001000\n  New best model saved!\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 526/526 [03:43<00:00,  2.35it/s, Loss=0.2164]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10:\n  Train Loss: 0.3146\n  Val Loss: 0.5705\n  Val BLEU: 0.0000\n  Val PPL: 1.77\n  Val CER: 0.0000\n  Learning Rate: 0.001000\nTraining completed!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n==================================================\nSTEP 4: Testing Translation\n==================================================\nInput Urdu: تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا\nTranslated Roman: tu kabhi khud ko bhi dekhe ega to jaega jaega jaega\nExpected Roman: tu kabhi khud ko bhi dekhega to dar jaega\n\nModel info saved to /kaggle/working/model_info.pkl\nTraining pipeline completed successfully!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ========================= MODEL TESTING FUNCTIONS =========================\n\nimport torch\nimport pickle\nimport numpy as np\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nimport editdistance\nfrom typing import List, Dict, Tuple, Optional\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nclass ModelTester:\n    \"\"\"Class for testing the trained Urdu-Roman translation model\"\"\"\n    \n    def __init__(self, model_path: str, bpe_model_path: str, device: torch.device):\n        \"\"\"\n        Initialize the model tester\n        \n        Args:\n            model_path: Path to the trained model checkpoint\n            bpe_model_path: Path to the trained BPE model\n            device: Device to run inference on\n        \"\"\"\n        self.device = device\n        \n        # Load BPE model\n        self.bpe = UrduRomanBPE()\n        self.bpe.load_model(bpe_model_path)\n        \n        # Load trained model\n        self._load_model(model_path)\n        \n        print(f\"Model loaded successfully on {device}\")\n        print(f\"Urdu vocab size: {len(self.bpe.urdu_vocab)}\")\n        print(f\"Roman vocab size: {len(self.bpe.roman_vocab)}\")\n    \n    def _load_model(self, model_path: str):\n        \"\"\"Load the trained model\"\"\"\n        checkpoint = torch.load(model_path, map_location=self.device)\n        \n        # Get vocabulary sizes\n        encoder_vocab_size = len(self.bpe.urdu_vocab)\n        decoder_vocab_size = len(self.bpe.roman_vocab)\n        \n        # Recreate model with same architecture\n        self.model = Seq2SeqModel(\n            encoder_vocab_size=encoder_vocab_size,\n            decoder_vocab_size=decoder_vocab_size,\n            embedding_dim=256,\n            encoder_hidden_dim=512,\n            decoder_hidden_dim=512,\n            encoder_layers=2,\n            decoder_layers=4,\n            dropout=0.3\n        )\n        \n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.model.to(self.device)\n        self.model.eval()\n        \n        # Store training history if available\n        self.train_losses = checkpoint.get('train_losses', [])\n        self.val_losses = checkpoint.get('val_losses', [])\n        self.val_bleus = checkpoint.get('val_bleus', [])\n        self.val_cers = checkpoint.get('val_cers', [])\n    \n    def translate_single(self, urdu_text: str, max_length: int = 50, \n                        show_attention: bool = False) -> Dict:\n        \"\"\"\n        Translate a single Urdu sentence to Roman Urdu\n        \n        Args:\n            urdu_text: Input Urdu text\n            max_length: Maximum length for translation\n            show_attention: Whether to return attention weights\n        \n        Returns:\n            Dictionary containing translation results\n        \"\"\"\n        # Preprocess and encode input\n        urdu_tokens = self.bpe.encode_urdu(urdu_text)\n        urdu_tokens = [self.bpe.urdu_vocab['<SOS>']] + urdu_tokens + [self.bpe.urdu_vocab['<EOS>']]\n        urdu_tensor = torch.tensor([urdu_tokens], device=self.device)\n        \n        # Generate translation\n        with torch.no_grad():\n            translated, attention_weights = self.model.translate(\n                urdu_tensor,\n                max_length=max_length,\n                sos_token=self.bpe.roman_vocab['<SOS>'],\n                eos_token=self.bpe.roman_vocab['<EOS>']\n            )\n        \n        # Decode translation\n        translated_tokens = translated[0].cpu().tolist()\n        \n        # Remove special tokens for cleaner output\n        clean_tokens = []\n        for token in translated_tokens:\n            if token == self.bpe.roman_vocab['<EOS>']:\n                break\n            if token not in [self.bpe.roman_vocab['<PAD>'], self.bpe.roman_vocab['<SOS>']]:\n                clean_tokens.append(token)\n        \n        translated_text = self.bpe.decode_roman(clean_tokens)\n        \n        result = {\n            'input_urdu': urdu_text,\n            'translated_roman': translated_text,\n            'input_tokens': urdu_tokens,\n            'output_tokens': clean_tokens\n        }\n        \n        if show_attention:\n            result['attention_weights'] = attention_weights[0].cpu().numpy()\n        \n        return result\n    \n    def translate_batch(self, urdu_texts: List[str], max_length: int = 50) -> List[Dict]:\n        \"\"\"\n        Translate a batch of Urdu sentences\n        \n        Args:\n            urdu_texts: List of Urdu texts\n            max_length: Maximum length for translation\n        \n        Returns:\n            List of translation results\n        \"\"\"\n        results = []\n        \n        for urdu_text in urdu_texts:\n            result = self.translate_single(urdu_text, max_length)\n            results.append(result)\n        \n        return results\n    \n    def interactive_test(self):\n        \"\"\"\n        Interactive testing mode - input Urdu text and get translations\n        \"\"\"\n        print(\"=\"*60)\n        print(\"INTERACTIVE TRANSLATION MODE\")\n        print(\"=\"*60)\n        print(\"Enter Urdu text to translate (type 'quit' to exit):\")\n        \n        while True:\n            try:\n                urdu_input = input(\"\\nUrdu: \").strip()\n                \n                if urdu_input.lower() in ['quit', 'exit', 'q']:\n                    print(\"Exiting interactive mode...\")\n                    break\n                \n                if not urdu_input:\n                    print(\"Please enter some text.\")\n                    continue\n                \n                result = self.translate_single(urdu_input, show_attention=False)\n                print(f\"Roman: {result['translated_roman']}\")\n                \n            except KeyboardInterrupt:\n                print(\"\\nExiting interactive mode...\")\n                break\n            except Exception as e:\n                print(f\"Error: {e}\")\n    \n    def evaluate_on_test_set(self, urdu_file: str, roman_file: str, \n                           max_samples: Optional[int] = None) -> Dict:\n        \"\"\"\n        Evaluate model on a test set\n        \n        Args:\n            urdu_file: Path to Urdu test file\n            roman_file: Path to Roman test file\n            max_samples: Maximum number of samples to evaluate\n        \n        Returns:\n            Dictionary containing evaluation metrics\n        \"\"\"\n        print(\"Evaluating on test set...\")\n        \n        # Load test data\n        with open(urdu_file, 'r', encoding='utf-8') as f:\n            urdu_lines = [line.strip() for line in f.readlines()]\n        \n        with open(roman_file, 'r', encoding='utf-8') as f:\n            roman_lines = [line.strip() for line in f.readlines()]\n        \n        # Limit samples if specified\n        if max_samples:\n            urdu_lines = urdu_lines[:max_samples]\n            roman_lines = roman_lines[:max_samples]\n        \n        print(f\"Evaluating on {len(urdu_lines)} samples...\")\n        \n        bleu_scores = []\n        edit_distances = []\n        total_chars_ref = 0\n        smoothie = SmoothingFunction().method4\n        \n        results = []\n        \n        for i, (urdu_text, roman_ref) in enumerate(zip(urdu_lines, roman_lines)):\n            if i % 100 == 0:\n                print(f\"Processed {i}/{len(urdu_lines)} samples...\")\n            \n            # Translate\n            result = self.translate_single(urdu_text)\n            roman_pred = result['translated_roman']\n            \n            # Calculate BLEU\n            ref_tokens = roman_ref.lower().split()\n            pred_tokens = roman_pred.lower().split()\n            \n            if pred_tokens:  # Avoid empty predictions\n                bleu = sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smoothie)\n                bleu_scores.append(bleu)\n            \n            # Calculate edit distance (for CER)\n            ed = editdistance.eval(roman_ref.lower(), roman_pred.lower())\n            edit_distances.append(ed)\n            total_chars_ref += len(roman_ref)\n            \n            # Store result for analysis\n            results.append({\n                'urdu': urdu_text,\n                'reference': roman_ref,\n                'prediction': roman_pred,\n                'bleu': bleu if pred_tokens else 0.0,\n                'edit_distance': ed\n            })\n        \n        # Calculate metrics\n        avg_bleu = np.mean(bleu_scores) if bleu_scores else 0.0\n        cer = sum(edit_distances) / total_chars_ref if total_chars_ref > 0 else 0.0\n        \n        evaluation_results = {\n            'avg_bleu': avg_bleu,\n            'cer': cer,\n            'num_samples': len(urdu_lines),\n            'bleu_scores': bleu_scores,\n            'edit_distances': edit_distances,\n            'detailed_results': results\n        }\n        \n        print(f\"\\nEvaluation Results:\")\n        print(f\"Average BLEU: {avg_bleu:.4f}\")\n        print(f\"Character Error Rate (CER): {cer:.4f}\")\n        print(f\"Samples evaluated: {len(urdu_lines)}\")\n        \n        return evaluation_results\n    \n    def show_examples(self, urdu_texts: List[str], expected_romans: Optional[List[str]] = None,\n                     num_examples: int = 5):\n        \"\"\"\n        Show translation examples with formatting\n        \n        Args:\n            urdu_texts: List of Urdu texts\n            expected_romans: Optional list of expected Roman translations\n            num_examples: Number of examples to show\n        \"\"\"\n        print(\"=\"*80)\n        print(\"TRANSLATION EXAMPLES\")\n        print(\"=\"*80)\n        \n        for i, urdu_text in enumerate(urdu_texts[:num_examples]):\n            result = self.translate_single(urdu_text)\n            \n            print(f\"\\nExample {i+1}:\")\n            print(f\"Urdu Input:  {urdu_text}\")\n            print(f\"Prediction:  {result['translated_roman']}\")\n            \n            if expected_romans and i < len(expected_romans):\n                print(f\"Expected:    {expected_romans[i]}\")\n                \n                # Calculate BLEU for this example\n                ref_tokens = expected_romans[i].lower().split()\n                pred_tokens = result['translated_roman'].lower().split()\n                if pred_tokens:\n                    bleu = sentence_bleu([ref_tokens], pred_tokens, \n                                       smoothing_function=SmoothingFunction().method4)\n                    print(f\"BLEU Score:  {bleu:.4f}\")\n            \n            print(\"-\" * 80)\n    \n    def visualize_attention(self, urdu_text: str, max_length: int = 50):\n        \"\"\"\n        Visualize attention weights for a translation\n        \n        Args:\n            urdu_text: Input Urdu text\n            max_length: Maximum translation length\n        \"\"\"\n        result = self.translate_single(urdu_text, max_length, show_attention=True)\n        \n        if 'attention_weights' not in result:\n            print(\"Attention weights not available\")\n            return\n        \n        attention = result['attention_weights']  # (tgt_len, src_len)\n        \n        # Get tokens for labeling\n        urdu_tokens = self.bpe.encode_urdu(urdu_text)\n        urdu_tokens = ['<SOS>'] + [self.bpe.decode_urdu([t]) for t in urdu_tokens] + ['<EOS>']\n        \n        roman_tokens = result['translated_roman'].split()\n        \n        # Create attention plot\n        plt.figure(figsize=(12, 8))\n        sns.heatmap(attention[:len(roman_tokens), :len(urdu_tokens)], \n                   xticklabels=urdu_tokens[:len(urdu_tokens)], \n                   yticklabels=roman_tokens[:len(roman_tokens)],\n                   cmap='Blues', cbar=True)\n        \n        plt.title(f'Attention Visualization\\nUrdu: {urdu_text}\\nRoman: {result[\"translated_roman\"]}')\n        plt.xlabel('Source (Urdu)')\n        plt.ylabel('Target (Roman)')\n        plt.xticks(rotation=45, ha='right')\n        plt.yticks(rotation=0)\n        plt.tight_layout()\n        plt.show()\n    \n    def plot_training_curves(self):\n        \"\"\"Plot training curves if available\"\"\"\n        if not self.train_losses:\n            print(\"Training history not available\")\n            return\n        \n        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n        \n        # Training and validation loss\n        axes[0, 0].plot(self.train_losses, label='Training Loss')\n        if self.val_losses:\n            axes[0, 0].plot(self.val_losses, label='Validation Loss')\n        axes[0, 0].set_title('Training and Validation Loss')\n        axes[0, 0].set_xlabel('Epoch')\n        axes[0, 0].set_ylabel('Loss')\n        axes[0, 0].legend()\n        axes[0, 0].grid(True)\n        \n        # BLEU scores\n        if self.val_bleus:\n            axes[0, 1].plot(self.val_bleus, label='Validation BLEU', color='green')\n            axes[0, 1].set_title('Validation BLEU Score')\n            axes[0, 1].set_xlabel('Epoch')\n            axes[0, 1].set_ylabel('BLEU')\n            axes[0, 1].legend()\n            axes[0, 1].grid(True)\n        \n        # CER scores\n        if self.val_cers:\n            axes[1, 0].plot(self.val_cers, label='Validation CER', color='red')\n            axes[1, 0].set_title('Validation Character Error Rate')\n            axes[1, 0].set_xlabel('Epoch')\n            axes[1, 0].set_ylabel('CER')\n            axes[1, 0].legend()\n            axes[1, 0].grid(True)\n        \n        # Combined metrics\n        if self.val_bleus and self.val_cers:\n            ax2 = axes[1, 1]\n            ax3 = ax2.twinx()\n            \n            line1 = ax2.plot(self.val_bleus, 'g-', label='BLEU')\n            line2 = ax3.plot(self.val_cers, 'r-', label='CER')\n            \n            ax2.set_xlabel('Epoch')\n            ax2.set_ylabel('BLEU', color='g')\n            ax3.set_ylabel('CER', color='r')\n            \n            lines = line1 + line2\n            labels = [l.get_label() for l in lines]\n            ax2.legend(lines, labels, loc='center right')\n            ax2.set_title('BLEU vs CER')\n            ax2.grid(True)\n        \n        plt.tight_layout()\n        plt.show()\n\n\n# ========================= USAGE FUNCTIONS =========================\n\ndef quick_test(model_path: str = '/kaggle/working/best_model.pt', \n               bpe_path: str = '/kaggle/working/bpe_model.pkl'):\n    \"\"\"\n    Quick test function with predefined examples\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    tester = ModelTester(model_path, bpe_path, device)\n    \n    # Test examples\n    test_sentences = [\n        \"تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا\",\n        \"میں آپ سے محبت کرتا ہوں\",\n        \"آج موسم بہت اچھا ہے\",\n        \"کل میں سکول جاؤں گا\",\n        \"یہ کتاب بہت دلچسپ ہے\"\n    ]\n    \n    expected_translations = [\n        \"tu kabhi khud ko bhi dekhega to dar jaega\",\n        \"main aap se mohabbat karta hun\",\n        \"aaj mausam bohat acha hai\",\n        \"kal main school jaunga\",\n        \"ye kitab bohat dilchasp hai\"\n    ]\n    \n    print(\"Quick Test Results:\")\n    tester.show_examples(test_sentences, expected_translations)\n    \n    return tester\n\ndef comprehensive_test(model_path: str = '/kaggle/working/best_model.pt',\n                      bpe_path: str = '/kaggle/working/bpe_model.pkl',\n                      test_urdu_file: str = '/kaggle/working/urdu.txt',\n                      test_roman_file: str = '/kaggle/working/roman.txt',\n                      max_samples: int = 1000):\n    \"\"\"\n    Comprehensive test with evaluation metrics\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    tester = ModelTester(model_path, bpe_path, device)\n    \n    # Show training curves\n    print(\"Training Curves:\")\n    tester.plot_training_curves()\n    \n    # Evaluate on test set\n    eval_results = tester.evaluate_on_test_set(\n        test_urdu_file, test_roman_file, max_samples\n    )\n    \n    # Show some examples\n    with open(test_urdu_file, 'r', encoding='utf-8') as f:\n        urdu_samples = [line.strip() for line in f.readlines()[:10]]\n    \n    with open(test_roman_file, 'r', encoding='utf-8') as f:\n        roman_samples = [line.strip() for line in f.readlines()[:10]]\n    \n    tester.show_examples(urdu_samples, roman_samples)\n    \n    return tester, eval_results\n\ndef interactive_mode(model_path: str = '/kaggle/working/best_model.pt',\n                    bpe_path: str = '/kaggle/working/bpe_model.pkl'):\n    \"\"\"\n    Start interactive translation mode\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    tester = ModelTester(model_path, bpe_path, device)\n    tester.interactive_test()\n    return tester\n\n\n# ========================= MAIN TESTING SCRIPT =========================\n\nif __name__ == \"__main__\":\n    print(\"Choose testing mode:\")\n    print(\"1. Quick Test (predefined examples)\")\n    print(\"2. Comprehensive Test (with evaluation)\")\n    print(\"3. Interactive Mode\")\n    print(\"4. Custom Test\")\n    \n    choice = input(\"Enter your choice (1-4): \").strip()\n    \n    if choice == '1':\n        tester = quick_test()\n    elif choice == '2':\n        tester, results = comprehensive_test()\n    elif choice == '3':\n        tester = interactive_mode()\n    elif choice == '4':\n        # Custom test example\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        tester = ModelTester('/kaggle/working/best_model.pt', \n                           '/kaggle/working/bpe_model.pkl', device)\n        \n        # Test your own sentences\n        custom_sentences = [\n            \"آپ کیسے ہیں؟\",\n            \"شکریہ آپ کا\"\n        ]\n        \n        results = tester.translate_batch(custom_sentences)\n        for result in results:\n            print(f\"Urdu: {result['input_urdu']}\")\n            print(f\"Roman: {result['translated_roman']}\")\n            print(\"-\" * 40)\n    \n    else:\n        print(\"Invalid choice!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:31:50.559238Z","iopub.execute_input":"2025-09-25T18:31:50.560100Z","iopub.status.idle":"2025-09-25T18:31:55.494531Z","shell.execute_reply.started":"2025-09-25T18:31:50.560064Z","shell.execute_reply":"2025-09-25T18:31:55.493867Z"}},"outputs":[{"name":"stdout","text":"Choose testing mode:\n1. Quick Test (predefined examples)\n2. Comprehensive Test (with evaluation)\n3. Interactive Mode\n4. Custom Test\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your choice (1-4):  1\n"},{"name":"stdout","text":"Model loaded from /kaggle/working/bpe_model.pkl\nModel loaded successfully on cuda\nUrdu vocab size: 4000\nRoman vocab size: 4000\nQuick Test Results:\n================================================================================\nTRANSLATION EXAMPLES\n================================================================================\n\nExample 1:\nUrdu Input:  تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا\nPrediction:  tu kabhi khud ko bhi dekhe ega to jaega jaega jaega\nExpected:    tu kabhi khud ko bhi dekhega to dar jaega\nBLEU Score:  0.3816\n--------------------------------------------------------------------------------\n\nExample 2:\nUrdu Input:  میں آپ سے محبت کرتا ہوں\nPrediction:  main aap se mohabbat karta huun huun huun meri karta huun\nExpected:    main aap se mohabbat karta hun\nBLEU Score:  0.3508\n--------------------------------------------------------------------------------\n\nExample 3:\nUrdu Input:  آج موسم بہت اچھا ہے\nPrediction:  aaj mausam bahut achchha hai hai hai aaj aaj hai hai aaj aaj mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam mausam\nExpected:    aaj mausam bohat acha hai\nBLEU Score:  0.0143\n--------------------------------------------------------------------------------\n\nExample 4:\nUrdu Input:  کل میں سکول جاؤں گا\nPrediction:  kal men pul tahi jaega nga nga kal tuega\nExpected:    kal main school jaunga\nBLEU Score:  0.0257\n--------------------------------------------------------------------------------\n\nExample 5:\nUrdu Input:  یہ کتاب بہت دلچسپ ہے\nPrediction:  ye kitab-e-bahut dilchsp hai hai hai sukitab hai\nExpected:    ye kitab bohat dilchasp hai\nBLEU Score:  0.0340\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"%%writefile app.py\nimport os\nimport io\nimport json\nimport time\nimport math\nimport pickle\nfrom typing import List, Optional, Dict, Tuple\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport streamlit as st\nimport matplotlib.pyplot as plt\n\n# -------------------------\n# Constants (Kaggle defaults)\n# -------------------------\nDEFAULT_BPE_PATH = \"/kaggle/working/bpe_model.pkl\"\nDEFAULT_CKPT_PATH = \"/kaggle/working/best_model.pt\"\nDEFAULT_URDU_FILE = \"/kaggle/working/urdu.txt\"\nDEFAULT_ROMAN_FILE = \"/kaggle/working/roman.txt\"\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# -------------------------\n# Minimal BPE loader (matches your pickled format)\n# -------------------------\nclass UrduRomanBPE:\n    def __init__(self):\n        self.vocab_size = None\n        self.urdu_vocab = {}\n        self.roman_vocab = {}\n        self.urdu_merges = []\n        self.roman_merges = []\n        self.special_tokens = ['<PAD>', '<UNK>', '<SOS>', '<EOS>']\n\n    def load_model(self, filepath: str):\n        with open(filepath, \"rb\") as f:\n            data = pickle.load(f)\n        self.urdu_vocab = data['urdu_vocab']\n        self.roman_vocab = data['roman_vocab']\n        self.urdu_merges = data['urdu_merges']\n        self.roman_merges = data['roman_merges']\n        self.vocab_size = data['vocab_size']\n        self.special_tokens = data.get('special_tokens', self.special_tokens)\n\n    # Lightweight preprocessors (same logic used during training)\n    def _preprocess_urdu_text(self, text: str) -> str:\n        import re\n        text = re.sub(r'\\s+', ' ', text.strip())\n        text = re.sub(r'[۔؟!]', ' <EOS> ', text)\n        text = re.sub(r'[،؍]', ' ', text)\n        return text.strip()\n\n    def _preprocess_roman_text(self, text: str) -> str:\n        import re\n        text = text.lower().strip()\n        text = re.sub(r'\\s+', ' ', text)\n        text = re.sub(r'[.!?]', ' <EOS> ', text)\n        text = re.sub(r'[,;:]', ' ', text)\n        return text.strip()\n\n    def _get_word_tokens(self, word: str) -> List[str]:\n        return list(word) + ['</w>']\n\n    def _apply_bpe(self, word: str, vocab: Dict, merges: List[Tuple[str, str]]) -> List[str]:\n        if not word:\n            return []\n        word_tokens = self._get_word_tokens(word)\n        if len(word_tokens) == 1:\n            return word_tokens\n        for merge in merges:\n            if len(word_tokens) == 1:\n                break\n            new_word_tokens = []\n            i = 0\n            while i < len(word_tokens):\n                if (i < len(word_tokens) - 1 and\n                    word_tokens[i] == merge[0] and\n                    word_tokens[i + 1] == merge[1]):\n                    new_word_tokens.append(''.join(merge))\n                    i += 2\n                else:\n                    new_word_tokens.append(word_tokens[i])\n                    i += 1\n            word_tokens = new_word_tokens\n        return word_tokens\n\n    def encode_urdu(self, text: str) -> List[int]:\n        text = self._preprocess_urdu_text(text)\n        tokens = []\n        for word in text.split():\n            if word in self.special_tokens:\n                tokens.append(self.urdu_vocab.get(word, self.urdu_vocab['<UNK>']))\n            else:\n                for tok in self._apply_bpe(word, self.urdu_vocab, self.urdu_merges):\n                    tokens.append(self.urdu_vocab.get(tok, self.urdu_vocab['<UNK>']))\n        return tokens\n\n    def decode_roman(self, token_ids: List[int]) -> str:\n        id_to_token = {idx: token for token, idx in self.roman_vocab.items()}\n        toks = [id_to_token.get(t, '<UNK>') for t in token_ids]\n        text = ''.join(toks).replace('</w>', ' ')\n        return text.strip()\n\n# -------------------------\n# Model (same architecture as training)\n# -------------------------\nclass BiLSTMEncoder(nn.Module):\n    def __init__(self, vocab_size: int, embedding_dim: int, hidden_dim: int,\n                 num_layers: int = 2, dropout: float = 0.3):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.bilstm = nn.LSTM(\n            input_size=embedding_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            bidirectional=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x: torch.Tensor, lengths: Optional[torch.Tensor] = None):\n        emb = self.dropout(self.embedding(x))\n        if lengths is not None:\n            emb = nn.utils.rnn.pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n        outputs, (hidden, cell) = self.bilstm(emb)\n        if lengths is not None:\n            outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n        return outputs, hidden, cell\n\nclass LSTMDecoder(nn.Module):\n    def __init__(self, vocab_size: int, embedding_dim: int, hidden_dim: int,\n                 encoder_hidden_dim: int, num_layers: int = 4, dropout: float = 0.3):\n        super().__init__()\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.lstm = nn.LSTM(\n            input_size=embedding_dim + encoder_hidden_dim * 2,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        self.attn = nn.Linear(hidden_dim + encoder_hidden_dim * 2, encoder_hidden_dim * 2)\n        self.out = nn.Linear(hidden_dim + encoder_hidden_dim * 2, vocab_size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x: torch.Tensor, hidden: torch.Tensor, cell: torch.Tensor,\n                encoder_outputs: torch.Tensor, mask: Optional[torch.Tensor] = None):\n        emb = self.dropout(self.embedding(x))  # (B,1,E)\n        top_hidden = hidden[-1].unsqueeze(1)   # (B,1,H)\n        enc_len = encoder_outputs.size(1)\n        top_rep = top_hidden.repeat(1, enc_len, 1)\n        att_in = torch.cat([top_rep, encoder_outputs], dim=2)\n        scores = self.attn(att_in)\n        scores = torch.sum(scores * encoder_outputs, dim=2)\n        if mask is not None:\n            scores.masked_fill_(mask == 0, -1e9)\n        att_w = F.softmax(scores, dim=1)                     # (B, enc_len)\n        context = torch.bmm(att_w.unsqueeze(1), encoder_outputs)  # (B,1,2H)\n        lstm_in = torch.cat([emb, context], dim=2)\n        lstm_out, (hidden, cell) = self.lstm(lstm_in, (hidden, cell))\n        out_in = torch.cat([lstm_out.squeeze(1), context.squeeze(1)], dim=1)\n        logits = self.out(out_in)                            # (B, V)\n        return logits, hidden, cell, att_w\n\nclass Seq2SeqModel(nn.Module):\n    def __init__(self, encoder_vocab_size: int, decoder_vocab_size: int,\n                 embedding_dim: int = 256, encoder_hidden_dim: int = 512,\n                 decoder_hidden_dim: int = 512, encoder_layers: int = 2,\n                 decoder_layers: int = 4, dropout: float = 0.3):\n        super().__init__()\n        self.encoder = BiLSTMEncoder(encoder_vocab_size, embedding_dim, encoder_hidden_dim,\n                                     num_layers=encoder_layers, dropout=dropout)\n        self.decoder = LSTMDecoder(decoder_vocab_size, embedding_dim, decoder_hidden_dim,\n                                   encoder_hidden_dim, num_layers=decoder_layers, dropout=dropout)\n        self.bridge_hidden = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n        self.bridge_cell = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n        self.decoder_layers = decoder_layers\n\n    def _bridge(self, h: torch.Tensor, c: torch.Tensor):\n        last_h = torch.cat([h[-2], h[-1]], dim=1)  # (B, 2H)\n        last_c = torch.cat([c[-2], c[-1]], dim=1)\n        dh = self.bridge_hidden(last_h).unsqueeze(0).repeat(self.decoder_layers, 1, 1)\n        dc = self.bridge_cell(last_c).unsqueeze(0).repeat(self.decoder_layers, 1, 1)\n        return dh, dc\n\n    def forward(self, src: torch.Tensor, tgt: torch.Tensor, src_lengths: Optional[torch.Tensor] = None,\n                teacher_forcing_ratio: float = 0.5):\n        B, T = tgt.size()\n        enc_out, enc_h, enc_c = self.encoder(src, src_lengths)\n        dec_h, dec_c = self._bridge(enc_h, enc_c)\n        if src_lengths is not None:\n            mask = torch.zeros(B, src.size(1), device=src.device)\n            for i, L in enumerate(src_lengths):\n                mask[i, :L] = 1\n        else:\n            mask = (src != 0).float()\n\n        outputs = []\n        attns = []\n        dec_in = tgt[:, 0].unsqueeze(1)\n        for t in range(1, T):\n            logit, dec_h, dec_c, att_w = self.decoder(dec_in, dec_h, dec_c, enc_out, mask)\n            outputs.append(logit)\n            attns.append(att_w)\n            if np.random.rand() < teacher_forcing_ratio:\n                dec_in = tgt[:, t].unsqueeze(1)\n            else:\n                dec_in = logit.argmax(dim=1).unsqueeze(1)\n        return torch.stack(outputs, dim=1), torch.stack(attns, dim=1)\n\n    def translate(self, src: torch.Tensor, max_length: int, sos_token: int, eos_token: int,\n                  src_lengths: Optional[torch.Tensor] = None):\n        self.eval()\n        with torch.no_grad():\n            B = src.size(0)\n            enc_out, enc_h, enc_c = self.encoder(src, src_lengths)\n            dec_h, dec_c = self._bridge(enc_h, enc_c)\n            if src_lengths is not None:\n                mask = torch.zeros(B, src.size(1), device=src.device)\n                for i, L in enumerate(src_lengths):\n                    mask[i, :L] = 1\n            else:\n                mask = (src != 0).float()\n            dec_in = torch.full((B, 1), sos_token, device=src.device, dtype=torch.long)\n            outputs = []\n            attns = []\n            for _ in range(max_length):\n                logit, dec_h, dec_c, att_w = self.decoder(dec_in, dec_h, dec_c, enc_out, mask)\n                pred = logit.argmax(dim=1)\n                outputs.append(pred)\n                attns.append(att_w)\n                dec_in = pred.unsqueeze(1)\n                if (pred == eos_token).all():\n                    break\n            return torch.stack(outputs, dim=1), torch.stack(attns, dim=1)\n\n# -------------------------\n# Caching: load artifacts\n# -------------------------\n@st.cache_resource(show_spinner=True)\ndef load_bpe(bpe_path: str):\n    bpe = UrduRomanBPE()\n    bpe.load_model(bpe_path)\n    return bpe\n\n@st.cache_resource(show_spinner=True)\ndef load_model(ckpt_path: str, bpe: UrduRomanBPE):\n    enc_vocab = len(bpe.urdu_vocab)\n    dec_vocab = len(bpe.roman_vocab)\n    model = Seq2SeqModel(encoder_vocab_size=enc_vocab, decoder_vocab_size=dec_vocab,\n                         embedding_dim=256, encoder_hidden_dim=512, decoder_hidden_dim=512,\n                         encoder_layers=2, decoder_layers=4, dropout=0.3)\n    ckpt = torch.load(ckpt_path, map_location=DEVICE)\n    model.load_state_dict(ckpt['model_state_dict'])\n    model.to(DEVICE)\n    model.eval()\n    history = {\n        'train_losses': ckpt.get('train_losses', []),\n        'val_losses': ckpt.get('val_losses', []),\n        'val_bleus': ckpt.get('val_bleus', []),\n        'val_cers': ckpt.get('val_cers', []),\n    }\n    return model, history\n\n# -------------------------\n# Helpers\n# -------------------------\ndef make_src_tensor(bpe: UrduRomanBPE, urdu_texts: List[str], max_len: int = 50) -> Tuple[torch.Tensor, torch.Tensor]:\n    sos = bpe.urdu_vocab['<SOS>']; eos = bpe.urdu_vocab['<EOS>']; pad = bpe.urdu_vocab['<PAD>']\n    seqs = []\n    lens = []\n    for t in urdu_texts:\n        ids = bpe.encode_urdu(t)\n        ids = [sos] + ids + [eos]\n        lens.append(min(len(ids), max_len))\n        ids = ids[:max_len]\n        if len(ids) < max_len:\n            ids = ids + [pad]*(max_len - len(ids))\n        seqs.append(ids)\n    tens = torch.tensor(seqs, dtype=torch.long, device=DEVICE)\n    lens = torch.tensor(lens, dtype=torch.long, device=DEVICE)\n    return tens, lens\n\ndef decode_pred_tokens(bpe: UrduRomanBPE, pred_ids: List[int]) -> str:\n    pad = bpe.roman_vocab['<PAD>']; sos = bpe.roman_vocab['<SOS>']; eos = bpe.roman_vocab['<EOS>']\n    cleaned = []\n    for t in pred_ids:\n        if t == eos:\n            break\n        if t in (pad, sos):\n            continue\n        cleaned.append(t)\n    return bpe.decode_roman(cleaned)\n\ndef draw_attention(attn: np.ndarray, urdu_tokens_vis: List[str], roman_tokens_vis: List[str]):\n    # attn: (tgt_len, src_len)\n    fig, ax = plt.subplots(figsize=(min(12, 1 + 0.6*len(urdu_tokens_vis)), min(8, 1 + 0.5*len(roman_tokens_vis))))\n    im = ax.imshow(attn, aspect='auto')\n    ax.set_xticks(np.arange(len(urdu_tokens_vis)))\n    ax.set_xticklabels(urdu_tokens_vis, rotation=45, ha='right')\n    ax.set_yticks(np.arange(len(roman_tokens_vis)))\n    ax.set_yticklabels(roman_tokens_vis)\n    ax.set_xlabel(\"Source (Urdu tokens incl. <SOS>/<EOS>)\")\n    ax.set_ylabel(\"Generated Roman tokens\")\n    ax.set_title(\"Attention heatmap\")\n    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n    st.pyplot(fig)\n\ndef urdu_token_visuals(bpe: UrduRomanBPE, urdu_text: str, max_len: int = 50) -> List[str]:\n    ids = bpe.encode_urdu(urdu_text)\n    ids = [bpe.urdu_vocab['<SOS>']] + ids + [bpe.urdu_vocab['<EOS>']]\n    # for visuals convert ids back to rough tokens\n    id2tok = {idx: tok for tok, idx in bpe.urdu_vocab.items()}\n    toks = [id2tok.get(i, '<UNK>') for i in ids][:max_len]\n    # merge char-BPEs for display: show raw bpe tokens\n    return toks\n\n# -------------------------\n# UI\n# -------------------------\nst.set_page_config(page_title=\"Urdu → Roman Urdu (Seq2Seq + BPE)\", page_icon=\"📝\", layout=\"wide\")\nst.title(\"📝 Urdu → Roman Urdu Translator (Seq2Seq + BPE)\")\nst.caption(f\"Device: **{DEVICE}** · Loads your `bpe_model.pkl` + `best_model.pt` from /kaggle/working by default.\")\n\nwith st.sidebar:\n    st.header(\"Artifacts\")\n    bpe_path = st.text_input(\"Path to BPE model (.pkl)\", value=DEFAULT_BPE_PATH)\n    ckpt_path = st.text_input(\"Path to trained checkpoint (.pt)\", value=DEFAULT_CKPT_PATH)\n    max_len = st.slider(\"Max sequence length\", min_value=16, max_value=200, value=50, step=2)\n    show_prob = st.checkbox(\"(For debug) show raw IDs\", value=False)\n\n    load_btn = st.button(\"Load / Reload Artifacts\")\n\nif 'bpe' not in st.session_state or load_btn:\n    try:\n        st.session_state.bpe = load_bpe(bpe_path)\n        st.success(\"BPE loaded.\")\n    except Exception as e:\n        st.error(f\"Failed to load BPE: {e}\")\n\nif 'model' not in st.session_state or load_btn:\n    try:\n        if 'bpe' in st.session_state:\n            st.session_state.model, st.session_state.history = load_model(ckpt_path, st.session_state.bpe)\n            st.success(\"Model loaded.\")\n        else:\n            st.warning(\"Load BPE first.\")\n    except Exception as e:\n        st.error(f\"Failed to load model: {e}\")\n\nbpe = st.session_state.get('bpe', None)\nmodel = st.session_state.get('model', None)\nhistory = st.session_state.get('history', {'train_losses':[], 'val_losses':[], 'val_bleus':[], 'val_cers':[]})\n\ncol1, col2 = st.columns([1,1])\n\n# ------------- Single translation -------------\nwith col1:\n    st.subheader(\"Single Translation\")\n    urdu_text = st.text_area(\"Urdu text\", value=\"تو کبھی خود کو بھی دیکھے گا تو ڈر جائے گا\", height=120)\n    run_single = st.button(\"Translate\")\n    if run_single and bpe is not None and model is not None:\n        src, src_len = make_src_tensor(bpe, [urdu_text], max_len=max_len)\n        sos_t = bpe.roman_vocab['<SOS>']; eos_t = bpe.roman_vocab['<EOS>']\n        t0 = time.time()\n        preds, attns = model.translate(src, max_length=max_len, sos_token=sos_t, eos_token=eos_t, src_lengths=src_len)\n        infer_ms = (time.time() - t0)*1000.0\n        pred_ids = preds[0].detach().cpu().tolist()\n        roman = decode_pred_tokens(bpe, pred_ids)\n        st.write(f\"**Roman:** {roman}\")\n        st.caption(f\"Inference: {infer_ms:.1f} ms\")\n        if show_prob:\n            st.code(f\"Pred IDs: {pred_ids}\")\n\n        # Attention heatmap\n        with st.expander(\"Show attention heatmap\"):\n            att_np = attns[0].detach().cpu().numpy()\n            ur_vis = urdu_token_visuals(bpe, urdu_text, max_len=max_len)\n            # roman tokens roughly by whitespace from decoded string\n            roman_vis = roman.split() if roman.strip() else [\"\"]\n            # clip to lengths\n            tgt_len = min(len(roman_vis), att_np.shape[0])\n            src_len_vis = min(len(ur_vis), att_np.shape[1])\n            draw_attention(att_np[:tgt_len, :src_len_vis], ur_vis[:src_len_vis], roman_vis[:tgt_len])\n\n# ------------- Batch translation -------------\nwith col2:\n    st.subheader(\"Batch Translation\")\n    st.caption(\"Enter one Urdu sentence per line.\")\n    batch_in = st.text_area(\"Batch input\", value=\"میں آپ سے محبت کرتا ہوں\\nآج موسم بہت اچھا ہے\", height=120)\n    max_items = st.number_input(\"Max lines to process\", min_value=1, max_value=128, value=8, step=1)\n    run_batch = st.button(\"Run batch\")\n    if run_batch and bpe is not None and model is not None:\n        lines = [x.strip() for x in batch_in.splitlines() if x.strip()][:max_items]\n        if not lines:\n            st.warning(\"No non-empty lines found.\")\n        else:\n            src, src_len = make_src_tensor(bpe, lines, max_len=max_len)\n            sos_t = bpe.roman_vocab['<SOS>']; eos_t = bpe.roman_vocab['<EOS>']\n            preds, attns = model.translate(src, max_length=max_len, sos_token=sos_t, eos_token=eos_t, src_lengths=src_len)\n            out = []\n            for i, line in enumerate(lines):\n                ids = preds[i].detach().cpu().tolist()\n                out.append((line, decode_pred_tokens(bpe, ids)))\n            st.markdown(\"**Results**\")\n            for ur, ro in out:\n                st.write(\"—\")\n                st.write(f\"**Urdu:** {ur}\")\n                st.write(f\"**Roman:** {ro}\")\n\nst.markdown(\"---\")\n# ------------- Quick evaluation -------------\nst.subheader(\"Quick Evaluation (optional)\")\nst.caption(\"Evaluates on top-N pairs from urdu.txt / roman.txt if those files exist.\")\n\neval_cols = st.columns([1,1,1])\nwith eval_cols[0]:\n    urdu_file = st.text_input(\"Urdu file\", value=DEFAULT_URDU_FILE)\nwith eval_cols[1]:\n    roman_file = st.text_input(\"Roman file\", value=DEFAULT_ROMAN_FILE)\nwith eval_cols[2]:\n    eval_N = st.number_input(\"Evaluate first N lines\", min_value=1, max_value=200, value=20, step=1)\n\nrun_eval = st.button(\"Run quick eval\")\nif run_eval and bpe is not None and model is not None:\n    if not (os.path.exists(urdu_file) and os.path.exists(roman_file)):\n        st.error(\"Files not found.\")\n    else:\n        with open(urdu_file, 'r', encoding='utf-8') as f:\n            ur_lines = [l.strip() for l in f.readlines()]\n        with open(roman_file, 'r', encoding='utf-8') as f:\n            ro_lines = [l.strip() for l in f.readlines()]\n        n = min(eval_N, len(ur_lines), len(ro_lines))\n        ur = ur_lines[:n]; ro_ref = ro_lines[:n]\n        src, src_len = make_src_tensor(bpe, ur, max_len=max_len)\n        sos_t = bpe.roman_vocab['<SOS>']; eos_t = bpe.roman_vocab['<EOS>']\n        preds, attns = model.translate(src, max_length=max_len, sos_token=sos_t, eos_token=eos_t, src_lengths=src_len)\n        preds_txt = [decode_pred_tokens(bpe, preds[i].detach().cpu().tolist()) for i in range(n)]\n        # show table\n        for i in range(n):\n            st.write(\"—\")\n            st.write(f\"**Urdu:** {ur[i]}\")\n            st.write(f\"**Ref:**  {ro_ref[i]}\")\n            st.write(f\"**Pred:** {preds_txt[i]}\")\n\nst.markdown(\"---\")\n# ------------- Training curves (if present in checkpoint) -------------\nst.subheader(\"Training Curves (from checkpoint)\")\nc1, c2, c3 = st.columns(3)\nwith c1:\n    if history['train_losses']:\n        fig = plt.figure()\n        plt.plot(history['train_losses'])\n        plt.title(\"Train Loss\")\n        plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n        st.pyplot(fig)\nwith c2:\n    if history['val_losses']:\n        fig = plt.figure()\n        plt.plot(history['val_losses'])\n        plt.title(\"Val Loss\")\n        plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n        st.pyplot(fig)\nwith c3:\n    if history['val_bleus']:\n        fig = plt.figure()\n        plt.plot(history['val_bleus'])\n        plt.title(\"Val BLEU\")\n        plt.xlabel(\"Epoch\"); plt.ylabel(\"BLEU\")\n        st.pyplot(fig)\n\nst.caption(\"If charts are empty, your checkpoint might not contain these histories.\")\n\nst.markdown(\"—\")\nst.caption(\"Built for your Kaggle notebook artifacts: `bpe_model.pkl`, `best_model.pt`, and optional `urdu.txt`/`roman.txt`.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:32:31.812983Z","iopub.execute_input":"2025-09-25T18:32:31.813418Z","iopub.status.idle":"2025-09-25T18:32:31.830054Z","shell.execute_reply.started":"2025-09-25T18:32:31.813394Z","shell.execute_reply":"2025-09-25T18:32:31.829172Z"}},"outputs":[{"name":"stdout","text":"Writing app.py\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!pip -q install streamlit pyngrok --upgrade\n\n# OPTIONAL: add your ngrok auth token for better stability\n# Get one free from https://dashboard.ngrok.com/get-started/your-authtoken\nNGROK_TOKEN = \"\" \nif NGROK_TOKEN:\n    import os\n    os.environ[\"NGROK_AUTHTOKEN\"] = NGROK_TOKEN\n\n# Start ngrok tunnel and run Streamlit\nfrom pyngrok import ngrok\npublic_url = ngrok.connect(8501)\nprint(\"Public URL:\", public_url)\n\n# Launch the app\n!streamlit run app.py --server.port 8501 --server.headless true &\n\n# Give Streamlit a few seconds to boot\nimport time; time.sleep(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:33:12.336843Z","iopub.execute_input":"2025-09-25T18:33:12.337103Z","iopub.status.idle":"2025-09-25T18:33:12.343699Z","shell.execute_reply.started":"2025-09-25T18:33:12.337084Z","shell.execute_reply":"2025-09-25T18:33:12.342763Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_36/1250499312.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    NGROK_TOKEN = \"\"\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+00A0\n"],"ename":"SyntaxError","evalue":"invalid non-printable character U+00A0 (1250499312.py, line 5)","output_type":"error"}],"execution_count":12}]}